{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1VB-IOQ1XaFXNHT1_fV9VJWgUQtXfkRgL","timestamp":1662247555475}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"ChQzpQtCTFK0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se definen 10 comentarios de algún restaurante\n","reviews = [\n","          'Never coming back!',\n","          'horrible service',\n","          'rude waitress',\n","          'cold food',\n","          'horrible food!',\n","          'awesome',\n","          'awesome services!',\n","          'rocks',\n","          'nice work',\n","          'couldn\\'t have done better'\n","]\n","\n","# Se definen sus etiquetas. 1 para positivo, 0 para negativo\n","labels = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"],"metadata":{"id":"z35iw-QxTLVo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Tokenización"],"metadata":{"id":"8RCztRec3w2Q"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"metadata":{"id":"ZuYz-htGwQeK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"Proceso de tokenizacion, preprocesamiento. Para tokenize\"\"\"\n","vocab_size = 50 #Tamaño del vocabulario, se puede usar con spacy. Cuantas palabras hay\n","oov_tok = '<OOV>' #Hace alución para out of vocabulary (es para las palabras que no se pueden usar). Fuera del vocabulario\n","padding_type = 'post' #Parecido a las redes neuronales convulucionales, es como crear el borde oscuro."],"metadata":{"id":"sWqxbb6vhIgQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok) #Taño del vocabulario y como nombrar a las palbras que quedarán fuera del vocabulario\n","tokenizer.fit_on_texts(reviews) #Pasamos la data limpia, ya normalizada\n","word_index = tokenizer.word_index #Extraemos atributos, donde se asocia a los tokens con un index"],"metadata":{"id":"TYffw71AhIc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pe-Qk8_OharY","outputId":"dedf610c-7385-4a07-dcd1-a180325c6316"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'<OOV>': 1,\n"," 'horrible': 2,\n"," 'food': 3,\n"," 'awesome': 4,\n"," 'never': 5,\n"," 'coming': 6,\n"," 'back': 7,\n"," 'service': 8,\n"," 'rude': 9,\n"," 'waitress': 10,\n"," 'cold': 11,\n"," 'services': 12,\n"," 'rocks': 13,\n"," 'nice': 14,\n"," 'work': 15,\n"," \"couldn't\": 16,\n"," 'have': 17,\n"," 'done': 18,\n"," 'better': 19}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["tokenizer.word_counts #Conteo de palabras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YTiFjDiC95cL","outputId":"2f326024-f467-4cf5-9382-41e2b1d10ec4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('never', 1),\n","             ('coming', 1),\n","             ('back', 1),\n","             ('horrible', 2),\n","             ('service', 1),\n","             ('rude', 1),\n","             ('waitress', 1),\n","             ('cold', 1),\n","             ('food', 2),\n","             ('awesome', 2),\n","             ('services', 1),\n","             ('rocks', 1),\n","             ('nice', 1),\n","             ('work', 1),\n","             (\"couldn't\", 1),\n","             ('have', 1),\n","             ('done', 1),\n","             ('better', 1)])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["vocab_size = len(word_index)\n","vocab_size #numero de palabras que conforman el corpues"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vj1EsyGshe9q","outputId":"9bb858fc-a064-498d-9aac-ee6ac270a0e7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["tokenized_reviews = tokenizer.texts_to_sequences(reviews)\n","tokenized_reviews #Indices asociados a las palabras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dk2QwXQBTO-l","outputId":"45c6005e-3717-40aa-d0e6-a36cda255f75"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[5, 6, 7],\n"," [2, 8],\n"," [9, 10],\n"," [11, 3],\n"," [2, 3],\n"," [4],\n"," [4, 12],\n"," [13],\n"," [14, 15],\n"," [16, 17, 18, 19]]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["max_length = max([len(x) for x in tokenized_reviews])\n","max_length #Maxima lonngitud de la secuencia mas larga"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQAVo9e7jNa9","outputId":"2f02b411-11df-44ca-a9a6-79484f6eb74c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["padded_reviews = pad_sequences(tokenized_reviews, maxlen=max_length, padding=padding_type)\n","print(padded_reviews) #Rellenamos con ceros la indexacion con el tamaño de la secuencia más larga"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K3UOK8HwTQ8B","outputId":"879ae9a6-b83c-4514-bd53-fb162af05a4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 5  6  7  0]\n"," [ 2  8  0  0]\n"," [ 9 10  0  0]\n"," [11  3  0  0]\n"," [ 2  3  0  0]\n"," [ 4  0  0  0]\n"," [ 4 12  0  0]\n"," [13  0  0  0]\n"," [14 15  0  0]\n"," [16 17 18 19]]\n"]}]},{"cell_type":"markdown","source":["#### Word Embeddings"],"metadata":{"id":"iBXfY1wf4Rwi"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Embedding, Dense"],"metadata":{"id":"B_mc17KOw2Dm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"Creamos nuestros word Embeddings.\"\"\"\n","embedding_layer = Embedding(input_dim=vocab_size+1, output_dim=8, input_length=max_length) #Capa nueva\n","#Dimension de entrada tamaño del vocabulario más un valor adicional para palabras fuera del vocabulario\n","#output dim determina cuanto va a tardar nuestro algoritmo a ser entrenado, son el numero de variables del vector continuo, buen tamaño 100\n","#longitud de entrada es la longitud maxima"],"metadata":{"id":"C6wrYe3yZ8Vm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential() #Instanciamos\n","model.add(embedding_layer) #Capa de incrustaciones\n","model.add(Flatten()) # Desenrrollamos, no se recomienda, se puede usar otras arquitecturas\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) #Clasificación binaria"],"metadata":{"id":"J3Ml4NCmTS_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UJx4UZYUaCde","outputId":"9116c9db-b3c1-4739-fa81-12a8856470e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 4, 8)              160       \n","                                                                 \n"," flatten (Flatten)           (None, 32)                0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 193\n","Trainable params: 193\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.fit(padded_reviews, labels, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ws_fRAAQTXgN","outputId":"bf6f5c6d-5251-4560-84c2-43ee16d56aed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 [==============================] - 4s 4s/step - loss: 0.6910 - accuracy: 0.6000\n","Epoch 2/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6892 - accuracy: 0.6000\n","Epoch 3/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6874 - accuracy: 0.7000\n","Epoch 4/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6857 - accuracy: 0.7000\n","Epoch 5/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6839 - accuracy: 0.7000\n","Epoch 6/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6821 - accuracy: 0.9000\n","Epoch 7/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6803 - accuracy: 0.9000\n","Epoch 8/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6785 - accuracy: 0.9000\n","Epoch 9/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6768 - accuracy: 1.0000\n","Epoch 10/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6750 - accuracy: 1.0000\n","Epoch 11/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6731 - accuracy: 1.0000\n","Epoch 12/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6713 - accuracy: 1.0000\n","Epoch 13/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6695 - accuracy: 1.0000\n","Epoch 14/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6676 - accuracy: 1.0000\n","Epoch 15/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6658 - accuracy: 1.0000\n","Epoch 16/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6639 - accuracy: 1.0000\n","Epoch 17/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6620 - accuracy: 1.0000\n","Epoch 18/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6601 - accuracy: 1.0000\n","Epoch 19/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6582 - accuracy: 1.0000\n","Epoch 20/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6563 - accuracy: 1.0000\n","Epoch 21/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6543 - accuracy: 1.0000\n","Epoch 22/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6524 - accuracy: 1.0000\n","Epoch 23/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6504 - accuracy: 1.0000\n","Epoch 24/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6484 - accuracy: 1.0000\n","Epoch 25/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6464 - accuracy: 1.0000\n","Epoch 26/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6443 - accuracy: 1.0000\n","Epoch 27/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6423 - accuracy: 1.0000\n","Epoch 28/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6402 - accuracy: 1.0000\n","Epoch 29/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6381 - accuracy: 1.0000\n","Epoch 30/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6360 - accuracy: 1.0000\n","Epoch 31/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6339 - accuracy: 1.0000\n","Epoch 32/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6317 - accuracy: 1.0000\n","Epoch 33/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6295 - accuracy: 1.0000\n","Epoch 34/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6273 - accuracy: 1.0000\n","Epoch 35/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.6251 - accuracy: 1.0000\n","Epoch 36/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6229 - accuracy: 1.0000\n","Epoch 37/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6207 - accuracy: 1.0000\n","Epoch 38/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6184 - accuracy: 1.0000\n","Epoch 39/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6161 - accuracy: 1.0000\n","Epoch 40/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6138 - accuracy: 1.0000\n","Epoch 41/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6114 - accuracy: 1.0000\n","Epoch 42/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6091 - accuracy: 1.0000\n","Epoch 43/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6067 - accuracy: 1.0000\n","Epoch 44/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6043 - accuracy: 1.0000\n","Epoch 45/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.6019 - accuracy: 1.0000\n","Epoch 46/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5995 - accuracy: 1.0000\n","Epoch 47/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.5970 - accuracy: 1.0000\n","Epoch 48/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.5946 - accuracy: 1.0000\n","Epoch 49/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.5921 - accuracy: 1.0000\n","Epoch 50/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5896 - accuracy: 1.0000\n","Epoch 51/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.5870 - accuracy: 1.0000\n","Epoch 52/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5845 - accuracy: 1.0000\n","Epoch 53/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5819 - accuracy: 1.0000\n","Epoch 54/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5794 - accuracy: 1.0000\n","Epoch 55/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.5768 - accuracy: 1.0000\n","Epoch 56/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5741 - accuracy: 1.0000\n","Epoch 57/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5715 - accuracy: 1.0000\n","Epoch 58/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.5688 - accuracy: 1.0000\n","Epoch 59/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5662 - accuracy: 1.0000\n","Epoch 60/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5635 - accuracy: 1.0000\n","Epoch 61/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5608 - accuracy: 1.0000\n","Epoch 62/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5580 - accuracy: 1.0000\n","Epoch 63/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5553 - accuracy: 1.0000\n","Epoch 64/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5525 - accuracy: 1.0000\n","Epoch 65/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5498 - accuracy: 1.0000\n","Epoch 66/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5470 - accuracy: 1.0000\n","Epoch 67/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.5442 - accuracy: 1.0000\n","Epoch 68/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5414 - accuracy: 1.0000\n","Epoch 69/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5385 - accuracy: 1.0000\n","Epoch 70/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5357 - accuracy: 1.0000\n","Epoch 71/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.5328 - accuracy: 1.0000\n","Epoch 72/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5300 - accuracy: 1.0000\n","Epoch 73/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5271 - accuracy: 1.0000\n","Epoch 74/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5242 - accuracy: 1.0000\n","Epoch 75/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5213 - accuracy: 1.0000\n","Epoch 76/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.5183 - accuracy: 1.0000\n","Epoch 77/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.5154 - accuracy: 1.0000\n","Epoch 78/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.5125 - accuracy: 1.0000\n","Epoch 79/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.5095 - accuracy: 1.0000\n","Epoch 80/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5066 - accuracy: 1.0000\n","Epoch 81/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.5036 - accuracy: 1.0000\n","Epoch 82/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5006 - accuracy: 1.0000\n","Epoch 83/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4976 - accuracy: 1.0000\n","Epoch 84/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4946 - accuracy: 1.0000\n","Epoch 85/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.4916 - accuracy: 1.0000\n","Epoch 86/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.4886 - accuracy: 1.0000\n","Epoch 87/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.4856 - accuracy: 1.0000\n","Epoch 88/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4826 - accuracy: 1.0000\n","Epoch 89/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.4795 - accuracy: 1.0000\n","Epoch 90/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.4765 - accuracy: 1.0000\n","Epoch 91/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4734 - accuracy: 1.0000\n","Epoch 92/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.4704 - accuracy: 1.0000\n","Epoch 93/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.4674 - accuracy: 1.0000\n","Epoch 94/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.4643 - accuracy: 1.0000\n","Epoch 95/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4612 - accuracy: 1.0000\n","Epoch 96/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.4582 - accuracy: 1.0000\n","Epoch 97/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.4551 - accuracy: 1.0000\n","Epoch 98/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.4521 - accuracy: 1.0000\n","Epoch 99/100\n","1/1 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 1.0000\n","Epoch 100/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4459 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f35505d9450>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["import pandas as pd\n","from scipy import spatial"],"metadata":{"id":"j2hEdTVhnOEM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y) #Similitud cosenoidal"],"metadata":{"id":"LPLumapBniGQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(embedding_layer.get_weights()[0].shape) #matriz de incrustaciones, observacion de la matriz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zpGUGcM0TdBm","outputId":"064f648c-b484-4bb0-9a73-b8c3a42f39db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(20, 8)\n"]}]},{"cell_type":"code","source":["pd.DataFrame((embedding_layer.get_weights()[0]), index=['<pad>']+list(word_index.keys()), columns=['dim_'+str(x) for x in range(1,9)])\n","#Vector continuo asociado a las palabras, similar a PCA"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":677},"id":"EvWol-oYtbDE","outputId":"56b4936c-a25b-49da-f469-d1d0c6e6dd9f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             dim_1     dim_2     dim_3     dim_4     dim_5     dim_6  \\\n","<pad>    -0.030751 -0.130159  0.121297  0.054825 -0.128418  0.063643   \n","<OOV>     0.038733 -0.028142 -0.022666 -0.022424  0.002987  0.005259   \n","horrible -0.102366 -0.111475  0.093545 -0.160318 -0.143454 -0.092147   \n","food      0.076558  0.142790 -0.148010 -0.124077  0.079903  0.128303   \n","awesome   0.101571  0.066223 -0.068894  0.149145  0.107159  0.108261   \n","never    -0.076121 -0.131378  0.069915 -0.089701 -0.156249 -0.077513   \n","coming    0.095250  0.132554 -0.136284 -0.073360  0.105109  0.136303   \n","back     -0.063298  0.156527  0.083629 -0.130288  0.111158  0.057961   \n","service   0.156683  0.153118 -0.065421 -0.136383  0.094168  0.114992   \n","rude     -0.126471 -0.143259  0.129160 -0.078165 -0.133796 -0.104050   \n","waitress  0.121309  0.147948 -0.082394 -0.137819  0.148666  0.085680   \n","cold     -0.085713 -0.097947  0.147969 -0.116799 -0.095798 -0.113105   \n","services -0.136040 -0.124713  0.157995  0.091923 -0.086059 -0.074639   \n","rocks     0.124219  0.103030 -0.121295  0.161864  0.103378  0.130556   \n","nice      0.103382  0.085164 -0.102409  0.123441  0.069734  0.105345   \n","work     -0.149844 -0.107447  0.077376  0.136718 -0.079846 -0.075235   \n","couldn't  0.123187  0.077180 -0.081693  0.126744  0.150058  0.073335   \n","have     -0.110833 -0.083782  0.082410  0.106597 -0.120158 -0.118061   \n","done      0.127690 -0.082821 -0.054317  0.045743 -0.153350 -0.058230   \n","better   -0.101620 -0.038439  0.000950 -0.131662  0.143823 -0.138865   \n","\n","             dim_7     dim_8  \n","<pad>     0.150049 -0.123110  \n","<OOV>    -0.026361  0.038195  \n","horrible -0.085164 -0.068161  \n","food     -0.123759  0.151828  \n","awesome   0.140760  0.129726  \n","never    -0.154104 -0.060421  \n","coming   -0.062908  0.147670  \n","back      0.118312  0.159569  \n","service  -0.062776  0.121672  \n","rude     -0.074201 -0.116594  \n","waitress -0.112551  0.096735  \n","cold     -0.140234 -0.059974  \n","services  0.136654 -0.159604  \n","rocks     0.088377  0.088143  \n","nice      0.131250  0.132137  \n","work      0.114751 -0.081959  \n","couldn't  0.088316  0.092218  \n","have      0.115497 -0.079297  \n","done     -0.110648 -0.106581  \n","better    0.042462 -0.145954  "],"text/html":["\n","  <div id=\"df-6d8a193b-b995-4751-b30d-3dcefd6af45d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dim_1</th>\n","      <th>dim_2</th>\n","      <th>dim_3</th>\n","      <th>dim_4</th>\n","      <th>dim_5</th>\n","      <th>dim_6</th>\n","      <th>dim_7</th>\n","      <th>dim_8</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>&lt;pad&gt;</th>\n","      <td>-0.030751</td>\n","      <td>-0.130159</td>\n","      <td>0.121297</td>\n","      <td>0.054825</td>\n","      <td>-0.128418</td>\n","      <td>0.063643</td>\n","      <td>0.150049</td>\n","      <td>-0.123110</td>\n","    </tr>\n","    <tr>\n","      <th>&lt;OOV&gt;</th>\n","      <td>0.038733</td>\n","      <td>-0.028142</td>\n","      <td>-0.022666</td>\n","      <td>-0.022424</td>\n","      <td>0.002987</td>\n","      <td>0.005259</td>\n","      <td>-0.026361</td>\n","      <td>0.038195</td>\n","    </tr>\n","    <tr>\n","      <th>horrible</th>\n","      <td>-0.102366</td>\n","      <td>-0.111475</td>\n","      <td>0.093545</td>\n","      <td>-0.160318</td>\n","      <td>-0.143454</td>\n","      <td>-0.092147</td>\n","      <td>-0.085164</td>\n","      <td>-0.068161</td>\n","    </tr>\n","    <tr>\n","      <th>food</th>\n","      <td>0.076558</td>\n","      <td>0.142790</td>\n","      <td>-0.148010</td>\n","      <td>-0.124077</td>\n","      <td>0.079903</td>\n","      <td>0.128303</td>\n","      <td>-0.123759</td>\n","      <td>0.151828</td>\n","    </tr>\n","    <tr>\n","      <th>awesome</th>\n","      <td>0.101571</td>\n","      <td>0.066223</td>\n","      <td>-0.068894</td>\n","      <td>0.149145</td>\n","      <td>0.107159</td>\n","      <td>0.108261</td>\n","      <td>0.140760</td>\n","      <td>0.129726</td>\n","    </tr>\n","    <tr>\n","      <th>never</th>\n","      <td>-0.076121</td>\n","      <td>-0.131378</td>\n","      <td>0.069915</td>\n","      <td>-0.089701</td>\n","      <td>-0.156249</td>\n","      <td>-0.077513</td>\n","      <td>-0.154104</td>\n","      <td>-0.060421</td>\n","    </tr>\n","    <tr>\n","      <th>coming</th>\n","      <td>0.095250</td>\n","      <td>0.132554</td>\n","      <td>-0.136284</td>\n","      <td>-0.073360</td>\n","      <td>0.105109</td>\n","      <td>0.136303</td>\n","      <td>-0.062908</td>\n","      <td>0.147670</td>\n","    </tr>\n","    <tr>\n","      <th>back</th>\n","      <td>-0.063298</td>\n","      <td>0.156527</td>\n","      <td>0.083629</td>\n","      <td>-0.130288</td>\n","      <td>0.111158</td>\n","      <td>0.057961</td>\n","      <td>0.118312</td>\n","      <td>0.159569</td>\n","    </tr>\n","    <tr>\n","      <th>service</th>\n","      <td>0.156683</td>\n","      <td>0.153118</td>\n","      <td>-0.065421</td>\n","      <td>-0.136383</td>\n","      <td>0.094168</td>\n","      <td>0.114992</td>\n","      <td>-0.062776</td>\n","      <td>0.121672</td>\n","    </tr>\n","    <tr>\n","      <th>rude</th>\n","      <td>-0.126471</td>\n","      <td>-0.143259</td>\n","      <td>0.129160</td>\n","      <td>-0.078165</td>\n","      <td>-0.133796</td>\n","      <td>-0.104050</td>\n","      <td>-0.074201</td>\n","      <td>-0.116594</td>\n","    </tr>\n","    <tr>\n","      <th>waitress</th>\n","      <td>0.121309</td>\n","      <td>0.147948</td>\n","      <td>-0.082394</td>\n","      <td>-0.137819</td>\n","      <td>0.148666</td>\n","      <td>0.085680</td>\n","      <td>-0.112551</td>\n","      <td>0.096735</td>\n","    </tr>\n","    <tr>\n","      <th>cold</th>\n","      <td>-0.085713</td>\n","      <td>-0.097947</td>\n","      <td>0.147969</td>\n","      <td>-0.116799</td>\n","      <td>-0.095798</td>\n","      <td>-0.113105</td>\n","      <td>-0.140234</td>\n","      <td>-0.059974</td>\n","    </tr>\n","    <tr>\n","      <th>services</th>\n","      <td>-0.136040</td>\n","      <td>-0.124713</td>\n","      <td>0.157995</td>\n","      <td>0.091923</td>\n","      <td>-0.086059</td>\n","      <td>-0.074639</td>\n","      <td>0.136654</td>\n","      <td>-0.159604</td>\n","    </tr>\n","    <tr>\n","      <th>rocks</th>\n","      <td>0.124219</td>\n","      <td>0.103030</td>\n","      <td>-0.121295</td>\n","      <td>0.161864</td>\n","      <td>0.103378</td>\n","      <td>0.130556</td>\n","      <td>0.088377</td>\n","      <td>0.088143</td>\n","    </tr>\n","    <tr>\n","      <th>nice</th>\n","      <td>0.103382</td>\n","      <td>0.085164</td>\n","      <td>-0.102409</td>\n","      <td>0.123441</td>\n","      <td>0.069734</td>\n","      <td>0.105345</td>\n","      <td>0.131250</td>\n","      <td>0.132137</td>\n","    </tr>\n","    <tr>\n","      <th>work</th>\n","      <td>-0.149844</td>\n","      <td>-0.107447</td>\n","      <td>0.077376</td>\n","      <td>0.136718</td>\n","      <td>-0.079846</td>\n","      <td>-0.075235</td>\n","      <td>0.114751</td>\n","      <td>-0.081959</td>\n","    </tr>\n","    <tr>\n","      <th>couldn't</th>\n","      <td>0.123187</td>\n","      <td>0.077180</td>\n","      <td>-0.081693</td>\n","      <td>0.126744</td>\n","      <td>0.150058</td>\n","      <td>0.073335</td>\n","      <td>0.088316</td>\n","      <td>0.092218</td>\n","    </tr>\n","    <tr>\n","      <th>have</th>\n","      <td>-0.110833</td>\n","      <td>-0.083782</td>\n","      <td>0.082410</td>\n","      <td>0.106597</td>\n","      <td>-0.120158</td>\n","      <td>-0.118061</td>\n","      <td>0.115497</td>\n","      <td>-0.079297</td>\n","    </tr>\n","    <tr>\n","      <th>done</th>\n","      <td>0.127690</td>\n","      <td>-0.082821</td>\n","      <td>-0.054317</td>\n","      <td>0.045743</td>\n","      <td>-0.153350</td>\n","      <td>-0.058230</td>\n","      <td>-0.110648</td>\n","      <td>-0.106581</td>\n","    </tr>\n","    <tr>\n","      <th>better</th>\n","      <td>-0.101620</td>\n","      <td>-0.038439</td>\n","      <td>0.000950</td>\n","      <td>-0.131662</td>\n","      <td>0.143823</td>\n","      <td>-0.138865</td>\n","      <td>0.042462</td>\n","      <td>-0.145954</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d8a193b-b995-4751-b30d-3dcefd6af45d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6d8a193b-b995-4751-b30d-3dcefd6af45d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6d8a193b-b995-4751-b30d-3dcefd6af45d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["\"\"\"Calculo de similitudes. me quede min 42\"\"\"\n","\n","computed_similarities = pd.DataFrame()\n","\n","for word1 in word_index.keys():\n","    for word2 in word_index.keys():\n","        idx1 = word_index[word1]\n","        idx2 = word_index[word2]\n","        embedding1 = embedding_layer.get_weights()[0][idx1]\n","        embedding2 = embedding_layer.get_weights()[0][idx2]\n","        similarity = cosine_similarity2(embedding1, embedding2)\n","        computed_similarities.loc[word1, word2] = similarity"],"metadata":{"id":"FhL4ADNanncK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def non_zero_green(val):\n","    return 'background-color: Aquamarine' if (val > 0.9) & (val < 1) else ''"],"metadata":{"id":"Jb3PzDVFr1T9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["computed_similarities.style.applymap(non_zero_green)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"id":"53N-c7pCqNK9","outputId":"e02873fe-8a94-4fdb-a051-7afc47808a03"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7f3550331f10>"],"text/html":["<style type=\"text/css\">\n","#T_01e4b_row1_col4, #T_01e4b_row1_col8, #T_01e4b_row1_col10, #T_01e4b_row2_col5, #T_01e4b_row2_col7, #T_01e4b_row2_col9, #T_01e4b_row3_col12, #T_01e4b_row3_col13, #T_01e4b_row3_col15, #T_01e4b_row4_col1, #T_01e4b_row4_col8, #T_01e4b_row4_col10, #T_01e4b_row5_col2, #T_01e4b_row5_col7, #T_01e4b_row5_col9, #T_01e4b_row7_col2, #T_01e4b_row7_col5, #T_01e4b_row7_col9, #T_01e4b_row8_col1, #T_01e4b_row8_col4, #T_01e4b_row8_col10, #T_01e4b_row9_col2, #T_01e4b_row9_col5, #T_01e4b_row9_col7, #T_01e4b_row10_col1, #T_01e4b_row10_col4, #T_01e4b_row10_col8, #T_01e4b_row11_col14, #T_01e4b_row11_col16, #T_01e4b_row12_col3, #T_01e4b_row12_col13, #T_01e4b_row12_col15, #T_01e4b_row13_col3, #T_01e4b_row13_col12, #T_01e4b_row13_col15, #T_01e4b_row14_col11, #T_01e4b_row14_col16, #T_01e4b_row15_col3, #T_01e4b_row15_col12, #T_01e4b_row15_col13, #T_01e4b_row16_col11, #T_01e4b_row16_col14 {\n","  background-color: Aquamarine;\n","}\n","</style>\n","<table id=\"T_01e4b_\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th class=\"col_heading level0 col0\" ><OOV></th>\n","      <th class=\"col_heading level0 col1\" >horrible</th>\n","      <th class=\"col_heading level0 col2\" >food</th>\n","      <th class=\"col_heading level0 col3\" >awesome</th>\n","      <th class=\"col_heading level0 col4\" >never</th>\n","      <th class=\"col_heading level0 col5\" >coming</th>\n","      <th class=\"col_heading level0 col6\" >back</th>\n","      <th class=\"col_heading level0 col7\" >service</th>\n","      <th class=\"col_heading level0 col8\" >rude</th>\n","      <th class=\"col_heading level0 col9\" >waitress</th>\n","      <th class=\"col_heading level0 col10\" >cold</th>\n","      <th class=\"col_heading level0 col11\" >services</th>\n","      <th class=\"col_heading level0 col12\" >rocks</th>\n","      <th class=\"col_heading level0 col13\" >nice</th>\n","      <th class=\"col_heading level0 col14\" >work</th>\n","      <th class=\"col_heading level0 col15\" >couldn't</th>\n","      <th class=\"col_heading level0 col16\" >have</th>\n","      <th class=\"col_heading level0 col17\" >done</th>\n","      <th class=\"col_heading level0 col18\" >better</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row0\" class=\"row_heading level0 row0\" ><OOV></th>\n","      <td id=\"T_01e4b_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n","      <td id=\"T_01e4b_row0_col1\" class=\"data row0 col1\" >-0.026866</td>\n","      <td id=\"T_01e4b_row0_col2\" class=\"data row0 col2\" >0.574915</td>\n","      <td id=\"T_01e4b_row0_col3\" class=\"data row0 col3\" >0.102471</td>\n","      <td id=\"T_01e4b_row0_col4\" class=\"data row0 col4\" >0.090509</td>\n","      <td id=\"T_01e4b_row0_col5\" class=\"data row0 col5\" >0.539410</td>\n","      <td id=\"T_01e4b_row0_col6\" class=\"data row0 col6\" >-0.091150</td>\n","      <td id=\"T_01e4b_row0_col7\" class=\"data row0 col7\" >0.544239</td>\n","      <td id=\"T_01e4b_row0_col8\" class=\"data row0 col8\" >-0.226016</td>\n","      <td id=\"T_01e4b_row0_col9\" class=\"data row0 col9\" >0.521528</td>\n","      <td id=\"T_01e4b_row0_col10\" class=\"data row0 col10\" >-0.033361</td>\n","      <td id=\"T_01e4b_row0_col11\" class=\"data row0 col11\" >-0.678108</td>\n","      <td id=\"T_01e4b_row0_col12\" class=\"data row0 col12\" >0.124422</td>\n","      <td id=\"T_01e4b_row0_col13\" class=\"data row0 col13\" >0.154133</td>\n","      <td id=\"T_01e4b_row0_col14\" class=\"data row0 col14\" >-0.644669</td>\n","      <td id=\"T_01e4b_row0_col15\" class=\"data row0 col15\" >0.165269</td>\n","      <td id=\"T_01e4b_row0_col16\" class=\"data row0 col16\" >-0.611046</td>\n","      <td id=\"T_01e4b_row0_col17\" class=\"data row0 col17\" >0.267406</td>\n","      <td id=\"T_01e4b_row0_col18\" class=\"data row0 col18\" >-0.307213</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row1\" class=\"row_heading level0 row1\" >horrible</th>\n","      <td id=\"T_01e4b_row1_col0\" class=\"data row1 col0\" >-0.026866</td>\n","      <td id=\"T_01e4b_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n","      <td id=\"T_01e4b_row1_col2\" class=\"data row1 col2\" >-0.368384</td>\n","      <td id=\"T_01e4b_row1_col3\" class=\"data row1 col3\" >-0.943888</td>\n","      <td id=\"T_01e4b_row1_col4\" class=\"data row1 col4\" >0.938738</td>\n","      <td id=\"T_01e4b_row1_col5\" class=\"data row1 col5\" >-0.566785</td>\n","      <td id=\"T_01e4b_row1_col6\" class=\"data row1 col6\" >-0.238115</td>\n","      <td id=\"T_01e4b_row1_col7\" class=\"data row1 col7\" >-0.423789</td>\n","      <td id=\"T_01e4b_row1_col8\" class=\"data row1 col8\" >0.940954</td>\n","      <td id=\"T_01e4b_row1_col9\" class=\"data row1 col9\" >-0.385170</td>\n","      <td id=\"T_01e4b_row1_col10\" class=\"data row1 col10\" >0.943249</td>\n","      <td id=\"T_01e4b_row1_col11\" class=\"data row1 col11\" >0.418621</td>\n","      <td id=\"T_01e4b_row1_col12\" class=\"data row1 col12\" >-0.978536</td>\n","      <td id=\"T_01e4b_row1_col13\" class=\"data row1 col13\" >-0.927748</td>\n","      <td id=\"T_01e4b_row1_col14\" class=\"data row1 col14\" >0.284343</td>\n","      <td id=\"T_01e4b_row1_col15\" class=\"data row1 col15\" >-0.980759</td>\n","      <td id=\"T_01e4b_row1_col16\" class=\"data row1 col16\" >0.381699</td>\n","      <td id=\"T_01e4b_row1_col17\" class=\"data row1 col17\" >0.315982</td>\n","      <td id=\"T_01e4b_row1_col18\" class=\"data row1 col18\" >0.361057</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row2\" class=\"row_heading level0 row2\" >food</th>\n","      <td id=\"T_01e4b_row2_col0\" class=\"data row2 col0\" >0.574915</td>\n","      <td id=\"T_01e4b_row2_col1\" class=\"data row2 col1\" >-0.368384</td>\n","      <td id=\"T_01e4b_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n","      <td id=\"T_01e4b_row2_col3\" class=\"data row2 col3\" >0.298980</td>\n","      <td id=\"T_01e4b_row2_col4\" class=\"data row2 col4\" >-0.335874</td>\n","      <td id=\"T_01e4b_row2_col5\" class=\"data row2 col5\" >0.970355</td>\n","      <td id=\"T_01e4b_row2_col6\" class=\"data row2 col6\" >0.407232</td>\n","      <td id=\"T_01e4b_row2_col7\" class=\"data row2 col7\" >0.923142</td>\n","      <td id=\"T_01e4b_row2_col8\" class=\"data row2 col8\" >-0.623756</td>\n","      <td id=\"T_01e4b_row2_col9\" class=\"data row2 col9\" >0.932963</td>\n","      <td id=\"T_01e4b_row2_col10\" class=\"data row2 col10\" >-0.379245</td>\n","      <td id=\"T_01e4b_row2_col11\" class=\"data row2 col11\" >-0.967346</td>\n","      <td id=\"T_01e4b_row2_col12\" class=\"data row2 col12\" >0.422416</td>\n","      <td id=\"T_01e4b_row2_col13\" class=\"data row2 col13\" >0.394771</td>\n","      <td id=\"T_01e4b_row2_col14\" class=\"data row2 col14\" >-0.920897</td>\n","      <td id=\"T_01e4b_row2_col15\" class=\"data row2 col15\" >0.393873</td>\n","      <td id=\"T_01e4b_row2_col16\" class=\"data row2 col16\" >-0.938926</td>\n","      <td id=\"T_01e4b_row2_col17\" class=\"data row2 col17\" >-0.220974</td>\n","      <td id=\"T_01e4b_row2_col18\" class=\"data row2 col18\" >-0.287265</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row3\" class=\"row_heading level0 row3\" >awesome</th>\n","      <td id=\"T_01e4b_row3_col0\" class=\"data row3 col0\" >0.102471</td>\n","      <td id=\"T_01e4b_row3_col1\" class=\"data row3 col1\" >-0.943888</td>\n","      <td id=\"T_01e4b_row3_col2\" class=\"data row3 col2\" >0.298980</td>\n","      <td id=\"T_01e4b_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n","      <td id=\"T_01e4b_row3_col4\" class=\"data row3 col4\" >-0.914900</td>\n","      <td id=\"T_01e4b_row3_col5\" class=\"data row3 col5\" >0.513033</td>\n","      <td id=\"T_01e4b_row3_col6\" class=\"data row3 col6\" >0.327913</td>\n","      <td id=\"T_01e4b_row3_col7\" class=\"data row3 col7\" >0.372839</td>\n","      <td id=\"T_01e4b_row3_col8\" class=\"data row3 col8\" >-0.901824</td>\n","      <td id=\"T_01e4b_row3_col9\" class=\"data row3 col9\" >0.271144</td>\n","      <td id=\"T_01e4b_row3_col10\" class=\"data row3 col10\" >-0.932040</td>\n","      <td id=\"T_01e4b_row3_col11\" class=\"data row3 col11\" >-0.338051</td>\n","      <td id=\"T_01e4b_row3_col12\" class=\"data row3 col12\" >0.954733</td>\n","      <td id=\"T_01e4b_row3_col13\" class=\"data row3 col13\" >0.982025</td>\n","      <td id=\"T_01e4b_row3_col14\" class=\"data row3 col14\" >-0.192428</td>\n","      <td id=\"T_01e4b_row3_col15\" class=\"data row3 col15\" >0.957747</td>\n","      <td id=\"T_01e4b_row3_col16\" class=\"data row3 col16\" >-0.282027</td>\n","      <td id=\"T_01e4b_row3_col17\" class=\"data row3 col17\" >-0.381295</td>\n","      <td id=\"T_01e4b_row3_col18\" class=\"data row3 col18\" >-0.466580</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row4\" class=\"row_heading level0 row4\" >never</th>\n","      <td id=\"T_01e4b_row4_col0\" class=\"data row4 col0\" >0.090509</td>\n","      <td id=\"T_01e4b_row4_col1\" class=\"data row4 col1\" >0.938738</td>\n","      <td id=\"T_01e4b_row4_col2\" class=\"data row4 col2\" >-0.335874</td>\n","      <td id=\"T_01e4b_row4_col3\" class=\"data row4 col3\" >-0.914900</td>\n","      <td id=\"T_01e4b_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n","      <td id=\"T_01e4b_row4_col5\" class=\"data row4 col5\" >-0.539842</td>\n","      <td id=\"T_01e4b_row4_col6\" class=\"data row4 col6\" >-0.477117</td>\n","      <td id=\"T_01e4b_row4_col7\" class=\"data row4 col7\" >-0.446305</td>\n","      <td id=\"T_01e4b_row4_col8\" class=\"data row4 col8\" >0.917084</td>\n","      <td id=\"T_01e4b_row4_col9\" class=\"data row4 col9\" >-0.391299</td>\n","      <td id=\"T_01e4b_row4_col10\" class=\"data row4 col10\" >0.931532</td>\n","      <td id=\"T_01e4b_row4_col11\" class=\"data row4 col11\" >0.345540</td>\n","      <td id=\"T_01e4b_row4_col12\" class=\"data row4 col12\" >-0.896779</td>\n","      <td id=\"T_01e4b_row4_col13\" class=\"data row4 col13\" >-0.899017</td>\n","      <td id=\"T_01e4b_row4_col14\" class=\"data row4 col14\" >0.262984</td>\n","      <td id=\"T_01e4b_row4_col15\" class=\"data row4 col15\" >-0.934167</td>\n","      <td id=\"T_01e4b_row4_col16\" class=\"data row4 col16\" >0.341331</td>\n","      <td id=\"T_01e4b_row4_col17\" class=\"data row4 col17\" >0.526293</td>\n","      <td id=\"T_01e4b_row4_col18\" class=\"data row4 col18\" >0.163737</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row5\" class=\"row_heading level0 row5\" >coming</th>\n","      <td id=\"T_01e4b_row5_col0\" class=\"data row5 col0\" >0.539410</td>\n","      <td id=\"T_01e4b_row5_col1\" class=\"data row5 col1\" >-0.566785</td>\n","      <td id=\"T_01e4b_row5_col2\" class=\"data row5 col2\" >0.970355</td>\n","      <td id=\"T_01e4b_row5_col3\" class=\"data row5 col3\" >0.513033</td>\n","      <td id=\"T_01e4b_row5_col4\" class=\"data row5 col4\" >-0.539842</td>\n","      <td id=\"T_01e4b_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n","      <td id=\"T_01e4b_row5_col6\" class=\"data row5 col6\" >0.454840</td>\n","      <td id=\"T_01e4b_row5_col7\" class=\"data row5 col7\" >0.933992</td>\n","      <td id=\"T_01e4b_row5_col8\" class=\"data row5 col8\" >-0.785454</td>\n","      <td id=\"T_01e4b_row5_col9\" class=\"data row5 col9\" >0.921016</td>\n","      <td id=\"T_01e4b_row5_col10\" class=\"data row5 col10\" >-0.572547</td>\n","      <td id=\"T_01e4b_row5_col11\" class=\"data row5 col11\" >-0.949810</td>\n","      <td id=\"T_01e4b_row5_col12\" class=\"data row5 col12\" >0.612932</td>\n","      <td id=\"T_01e4b_row5_col13\" class=\"data row5 col13\" >0.589930</td>\n","      <td id=\"T_01e4b_row5_col14\" class=\"data row5 col14\" >-0.888434</td>\n","      <td id=\"T_01e4b_row5_col15\" class=\"data row5 col15\" >0.596495</td>\n","      <td id=\"T_01e4b_row5_col16\" class=\"data row5 col16\" >-0.928947</td>\n","      <td id=\"T_01e4b_row5_col17\" class=\"data row5 col17\" >-0.302195</td>\n","      <td id=\"T_01e4b_row5_col18\" class=\"data row5 col18\" >-0.336632</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row6\" class=\"row_heading level0 row6\" >back</th>\n","      <td id=\"T_01e4b_row6_col0\" class=\"data row6 col0\" >-0.091150</td>\n","      <td id=\"T_01e4b_row6_col1\" class=\"data row6 col1\" >-0.238115</td>\n","      <td id=\"T_01e4b_row6_col2\" class=\"data row6 col2\" >0.407232</td>\n","      <td id=\"T_01e4b_row6_col3\" class=\"data row6 col3\" >0.327913</td>\n","      <td id=\"T_01e4b_row6_col4\" class=\"data row6 col4\" >-0.477117</td>\n","      <td id=\"T_01e4b_row6_col5\" class=\"data row6 col5\" >0.454840</td>\n","      <td id=\"T_01e4b_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n","      <td id=\"T_01e4b_row6_col7\" class=\"data row6 col7\" >0.505806</td>\n","      <td id=\"T_01e4b_row6_col8\" class=\"data row6 col8\" >-0.388476</td>\n","      <td id=\"T_01e4b_row6_col9\" class=\"data row6 col9\" >0.453042</td>\n","      <td id=\"T_01e4b_row6_col10\" class=\"data row6 col10\" >-0.250386</td>\n","      <td id=\"T_01e4b_row6_col11\" class=\"data row6 col11\" >-0.283779</td>\n","      <td id=\"T_01e4b_row6_col12\" class=\"data row6 col12\" >0.189174</td>\n","      <td id=\"T_01e4b_row6_col13\" class=\"data row6 col13\" >0.323636</td>\n","      <td id=\"T_01e4b_row6_col14\" class=\"data row6 col14\" >-0.318086</td>\n","      <td id=\"T_01e4b_row6_col15\" class=\"data row6 col15\" >0.277634</td>\n","      <td id=\"T_01e4b_row6_col16\" class=\"data row6 col16\" >-0.336575</td>\n","      <td id=\"T_01e4b_row6_col17\" class=\"data row6 col17\" >-0.891516</td>\n","      <td id=\"T_01e4b_row6_col18\" class=\"data row6 col18\" >0.073485</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row7\" class=\"row_heading level0 row7\" >service</th>\n","      <td id=\"T_01e4b_row7_col0\" class=\"data row7 col0\" >0.544239</td>\n","      <td id=\"T_01e4b_row7_col1\" class=\"data row7 col1\" >-0.423789</td>\n","      <td id=\"T_01e4b_row7_col2\" class=\"data row7 col2\" >0.923142</td>\n","      <td id=\"T_01e4b_row7_col3\" class=\"data row7 col3\" >0.372839</td>\n","      <td id=\"T_01e4b_row7_col4\" class=\"data row7 col4\" >-0.446305</td>\n","      <td id=\"T_01e4b_row7_col5\" class=\"data row7 col5\" >0.933992</td>\n","      <td id=\"T_01e4b_row7_col6\" class=\"data row7 col6\" >0.505806</td>\n","      <td id=\"T_01e4b_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n","      <td id=\"T_01e4b_row7_col8\" class=\"data row7 col8\" >-0.673064</td>\n","      <td id=\"T_01e4b_row7_col9\" class=\"data row7 col9\" >0.962374</td>\n","      <td id=\"T_01e4b_row7_col10\" class=\"data row7 col10\" >-0.408702</td>\n","      <td id=\"T_01e4b_row7_col11\" class=\"data row7 col11\" >-0.915158</td>\n","      <td id=\"T_01e4b_row7_col12\" class=\"data row7 col12\" >0.459719</td>\n","      <td id=\"T_01e4b_row7_col13\" class=\"data row7 col13\" >0.444464</td>\n","      <td id=\"T_01e4b_row7_col14\" class=\"data row7 col14\" >-0.964040</td>\n","      <td id=\"T_01e4b_row7_col15\" class=\"data row7 col15\" >0.478060</td>\n","      <td id=\"T_01e4b_row7_col16\" class=\"data row7 col16\" >-0.940688</td>\n","      <td id=\"T_01e4b_row7_col17\" class=\"data row7 col17\" >-0.240134</td>\n","      <td id=\"T_01e4b_row7_col18\" class=\"data row7 col18\" >-0.263682</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row8\" class=\"row_heading level0 row8\" >rude</th>\n","      <td id=\"T_01e4b_row8_col0\" class=\"data row8 col0\" >-0.226016</td>\n","      <td id=\"T_01e4b_row8_col1\" class=\"data row8 col1\" >0.940954</td>\n","      <td id=\"T_01e4b_row8_col2\" class=\"data row8 col2\" >-0.623756</td>\n","      <td id=\"T_01e4b_row8_col3\" class=\"data row8 col3\" >-0.901824</td>\n","      <td id=\"T_01e4b_row8_col4\" class=\"data row8 col4\" >0.917084</td>\n","      <td id=\"T_01e4b_row8_col5\" class=\"data row8 col5\" >-0.785454</td>\n","      <td id=\"T_01e4b_row8_col6\" class=\"data row8 col6\" >-0.388476</td>\n","      <td id=\"T_01e4b_row8_col7\" class=\"data row8 col7\" >-0.673064</td>\n","      <td id=\"T_01e4b_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n","      <td id=\"T_01e4b_row8_col9\" class=\"data row8 col9\" >-0.616953</td>\n","      <td id=\"T_01e4b_row8_col10\" class=\"data row8 col10\" >0.929455</td>\n","      <td id=\"T_01e4b_row8_col11\" class=\"data row8 col11\" >0.658159</td>\n","      <td id=\"T_01e4b_row8_col12\" class=\"data row8 col12\" >-0.947989</td>\n","      <td id=\"T_01e4b_row8_col13\" class=\"data row8 col13\" >-0.931025</td>\n","      <td id=\"T_01e4b_row8_col14\" class=\"data row8 col14\" >0.540021</td>\n","      <td id=\"T_01e4b_row8_col15\" class=\"data row8 col15\" >-0.948227</td>\n","      <td id=\"T_01e4b_row8_col16\" class=\"data row8 col16\" >0.599535</td>\n","      <td id=\"T_01e4b_row8_col17\" class=\"data row8 col17\" >0.352135</td>\n","      <td id=\"T_01e4b_row8_col18\" class=\"data row8 col18\" >0.380753</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row9\" class=\"row_heading level0 row9\" >waitress</th>\n","      <td id=\"T_01e4b_row9_col0\" class=\"data row9 col0\" >0.521528</td>\n","      <td id=\"T_01e4b_row9_col1\" class=\"data row9 col1\" >-0.385170</td>\n","      <td id=\"T_01e4b_row9_col2\" class=\"data row9 col2\" >0.932963</td>\n","      <td id=\"T_01e4b_row9_col3\" class=\"data row9 col3\" >0.271144</td>\n","      <td id=\"T_01e4b_row9_col4\" class=\"data row9 col4\" >-0.391299</td>\n","      <td id=\"T_01e4b_row9_col5\" class=\"data row9 col5\" >0.921016</td>\n","      <td id=\"T_01e4b_row9_col6\" class=\"data row9 col6\" >0.453042</td>\n","      <td id=\"T_01e4b_row9_col7\" class=\"data row9 col7\" >0.962374</td>\n","      <td id=\"T_01e4b_row9_col8\" class=\"data row9 col8\" >-0.616953</td>\n","      <td id=\"T_01e4b_row9_col9\" class=\"data row9 col9\" >1.000000</td>\n","      <td id=\"T_01e4b_row9_col10\" class=\"data row9 col10\" >-0.331214</td>\n","      <td id=\"T_01e4b_row9_col11\" class=\"data row9 col11\" >-0.929005</td>\n","      <td id=\"T_01e4b_row9_col12\" class=\"data row9 col12\" >0.384947</td>\n","      <td id=\"T_01e4b_row9_col13\" class=\"data row9 col13\" >0.327813</td>\n","      <td id=\"T_01e4b_row9_col14\" class=\"data row9 col14\" >-0.969367</td>\n","      <td id=\"T_01e4b_row9_col15\" class=\"data row9 col15\" >0.431398</td>\n","      <td id=\"T_01e4b_row9_col16\" class=\"data row9 col16\" >-0.972917</td>\n","      <td id=\"T_01e4b_row9_col17\" class=\"data row9 col17\" >-0.256005</td>\n","      <td id=\"T_01e4b_row9_col18\" class=\"data row9 col18\" >-0.091362</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row10\" class=\"row_heading level0 row10\" >cold</th>\n","      <td id=\"T_01e4b_row10_col0\" class=\"data row10 col0\" >-0.033361</td>\n","      <td id=\"T_01e4b_row10_col1\" class=\"data row10 col1\" >0.943249</td>\n","      <td id=\"T_01e4b_row10_col2\" class=\"data row10 col2\" >-0.379245</td>\n","      <td id=\"T_01e4b_row10_col3\" class=\"data row10 col3\" >-0.932040</td>\n","      <td id=\"T_01e4b_row10_col4\" class=\"data row10 col4\" >0.931532</td>\n","      <td id=\"T_01e4b_row10_col5\" class=\"data row10 col5\" >-0.572547</td>\n","      <td id=\"T_01e4b_row10_col6\" class=\"data row10 col6\" >-0.250386</td>\n","      <td id=\"T_01e4b_row10_col7\" class=\"data row10 col7\" >-0.408702</td>\n","      <td id=\"T_01e4b_row10_col8\" class=\"data row10 col8\" >0.929455</td>\n","      <td id=\"T_01e4b_row10_col9\" class=\"data row10 col9\" >-0.331214</td>\n","      <td id=\"T_01e4b_row10_col10\" class=\"data row10 col10\" >1.000000</td>\n","      <td id=\"T_01e4b_row10_col11\" class=\"data row10 col11\" >0.395264</td>\n","      <td id=\"T_01e4b_row10_col12\" class=\"data row10 col12\" >-0.962834</td>\n","      <td id=\"T_01e4b_row10_col13\" class=\"data row10 col13\" >-0.955243</td>\n","      <td id=\"T_01e4b_row10_col14\" class=\"data row10 col14\" >0.253282</td>\n","      <td id=\"T_01e4b_row10_col15\" class=\"data row10 col15\" >-0.922720</td>\n","      <td id=\"T_01e4b_row10_col16\" class=\"data row10 col16\" >0.337853</td>\n","      <td id=\"T_01e4b_row10_col17\" class=\"data row10 col17\" >0.307556</td>\n","      <td id=\"T_01e4b_row10_col18\" class=\"data row10 col18\" >0.344716</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row11\" class=\"row_heading level0 row11\" >services</th>\n","      <td id=\"T_01e4b_row11_col0\" class=\"data row11 col0\" >-0.678108</td>\n","      <td id=\"T_01e4b_row11_col1\" class=\"data row11 col1\" >0.418621</td>\n","      <td id=\"T_01e4b_row11_col2\" class=\"data row11 col2\" >-0.967346</td>\n","      <td id=\"T_01e4b_row11_col3\" class=\"data row11 col3\" >-0.338051</td>\n","      <td id=\"T_01e4b_row11_col4\" class=\"data row11 col4\" >0.345540</td>\n","      <td id=\"T_01e4b_row11_col5\" class=\"data row11 col5\" >-0.949810</td>\n","      <td id=\"T_01e4b_row11_col6\" class=\"data row11 col6\" >-0.283779</td>\n","      <td id=\"T_01e4b_row11_col7\" class=\"data row11 col7\" >-0.915158</td>\n","      <td id=\"T_01e4b_row11_col8\" class=\"data row11 col8\" >0.658159</td>\n","      <td id=\"T_01e4b_row11_col9\" class=\"data row11 col9\" >-0.929005</td>\n","      <td id=\"T_01e4b_row11_col10\" class=\"data row11 col10\" >0.395264</td>\n","      <td id=\"T_01e4b_row11_col11\" class=\"data row11 col11\" >1.000000</td>\n","      <td id=\"T_01e4b_row11_col12\" class=\"data row11 col12\" >-0.466367</td>\n","      <td id=\"T_01e4b_row11_col13\" class=\"data row11 col13\" >-0.429288</td>\n","      <td id=\"T_01e4b_row11_col14\" class=\"data row11 col14\" >0.939577</td>\n","      <td id=\"T_01e4b_row11_col15\" class=\"data row11 col15\" >-0.464687</td>\n","      <td id=\"T_01e4b_row11_col16\" class=\"data row11 col16\" >0.929711</td>\n","      <td id=\"T_01e4b_row11_col17\" class=\"data row11 col17\" >0.080929</td>\n","      <td id=\"T_01e4b_row11_col18\" class=\"data row11 col18\" >0.314865</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row12\" class=\"row_heading level0 row12\" >rocks</th>\n","      <td id=\"T_01e4b_row12_col0\" class=\"data row12 col0\" >0.124422</td>\n","      <td id=\"T_01e4b_row12_col1\" class=\"data row12 col1\" >-0.978536</td>\n","      <td id=\"T_01e4b_row12_col2\" class=\"data row12 col2\" >0.422416</td>\n","      <td id=\"T_01e4b_row12_col3\" class=\"data row12 col3\" >0.954733</td>\n","      <td id=\"T_01e4b_row12_col4\" class=\"data row12 col4\" >-0.896779</td>\n","      <td id=\"T_01e4b_row12_col5\" class=\"data row12 col5\" >0.612932</td>\n","      <td id=\"T_01e4b_row12_col6\" class=\"data row12 col6\" >0.189174</td>\n","      <td id=\"T_01e4b_row12_col7\" class=\"data row12 col7\" >0.459719</td>\n","      <td id=\"T_01e4b_row12_col8\" class=\"data row12 col8\" >-0.947989</td>\n","      <td id=\"T_01e4b_row12_col9\" class=\"data row12 col9\" >0.384947</td>\n","      <td id=\"T_01e4b_row12_col10\" class=\"data row12 col10\" >-0.962834</td>\n","      <td id=\"T_01e4b_row12_col11\" class=\"data row12 col11\" >-0.466367</td>\n","      <td id=\"T_01e4b_row12_col12\" class=\"data row12 col12\" >1.000000</td>\n","      <td id=\"T_01e4b_row12_col13\" class=\"data row12 col13\" >0.963208</td>\n","      <td id=\"T_01e4b_row12_col14\" class=\"data row12 col14\" >-0.321146</td>\n","      <td id=\"T_01e4b_row12_col15\" class=\"data row12 col15\" >0.960960</td>\n","      <td id=\"T_01e4b_row12_col16\" class=\"data row12 col16\" >-0.409564</td>\n","      <td id=\"T_01e4b_row12_col17\" class=\"data row12 col17\" >-0.228703</td>\n","      <td id=\"T_01e4b_row12_col18\" class=\"data row12 col18\" >-0.499648</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row13\" class=\"row_heading level0 row13\" >nice</th>\n","      <td id=\"T_01e4b_row13_col0\" class=\"data row13 col0\" >0.154133</td>\n","      <td id=\"T_01e4b_row13_col1\" class=\"data row13 col1\" >-0.927748</td>\n","      <td id=\"T_01e4b_row13_col2\" class=\"data row13 col2\" >0.394771</td>\n","      <td id=\"T_01e4b_row13_col3\" class=\"data row13 col3\" >0.982025</td>\n","      <td id=\"T_01e4b_row13_col4\" class=\"data row13 col4\" >-0.899017</td>\n","      <td id=\"T_01e4b_row13_col5\" class=\"data row13 col5\" >0.589930</td>\n","      <td id=\"T_01e4b_row13_col6\" class=\"data row13 col6\" >0.323636</td>\n","      <td id=\"T_01e4b_row13_col7\" class=\"data row13 col7\" >0.444464</td>\n","      <td id=\"T_01e4b_row13_col8\" class=\"data row13 col8\" >-0.931025</td>\n","      <td id=\"T_01e4b_row13_col9\" class=\"data row13 col9\" >0.327813</td>\n","      <td id=\"T_01e4b_row13_col10\" class=\"data row13 col10\" >-0.955243</td>\n","      <td id=\"T_01e4b_row13_col11\" class=\"data row13 col11\" >-0.429288</td>\n","      <td id=\"T_01e4b_row13_col12\" class=\"data row13 col12\" >0.963208</td>\n","      <td id=\"T_01e4b_row13_col13\" class=\"data row13 col13\" >1.000000</td>\n","      <td id=\"T_01e4b_row13_col14\" class=\"data row13 col14\" >-0.269930</td>\n","      <td id=\"T_01e4b_row13_col15\" class=\"data row13 col15\" >0.935797</td>\n","      <td id=\"T_01e4b_row13_col16\" class=\"data row13 col16\" >-0.334266</td>\n","      <td id=\"T_01e4b_row13_col17\" class=\"data row13 col17\" >-0.325863</td>\n","      <td id=\"T_01e4b_row13_col18\" class=\"data row13 col18\" >-0.519434</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row14\" class=\"row_heading level0 row14\" >work</th>\n","      <td id=\"T_01e4b_row14_col0\" class=\"data row14 col0\" >-0.644669</td>\n","      <td id=\"T_01e4b_row14_col1\" class=\"data row14 col1\" >0.284343</td>\n","      <td id=\"T_01e4b_row14_col2\" class=\"data row14 col2\" >-0.920897</td>\n","      <td id=\"T_01e4b_row14_col3\" class=\"data row14 col3\" >-0.192428</td>\n","      <td id=\"T_01e4b_row14_col4\" class=\"data row14 col4\" >0.262984</td>\n","      <td id=\"T_01e4b_row14_col5\" class=\"data row14 col5\" >-0.888434</td>\n","      <td id=\"T_01e4b_row14_col6\" class=\"data row14 col6\" >-0.318086</td>\n","      <td id=\"T_01e4b_row14_col7\" class=\"data row14 col7\" >-0.964040</td>\n","      <td id=\"T_01e4b_row14_col8\" class=\"data row14 col8\" >0.540021</td>\n","      <td id=\"T_01e4b_row14_col9\" class=\"data row14 col9\" >-0.969367</td>\n","      <td id=\"T_01e4b_row14_col10\" class=\"data row14 col10\" >0.253282</td>\n","      <td id=\"T_01e4b_row14_col11\" class=\"data row14 col11\" >0.939577</td>\n","      <td id=\"T_01e4b_row14_col12\" class=\"data row14 col12\" >-0.321146</td>\n","      <td id=\"T_01e4b_row14_col13\" class=\"data row14 col13\" >-0.269930</td>\n","      <td id=\"T_01e4b_row14_col14\" class=\"data row14 col14\" >1.000000</td>\n","      <td id=\"T_01e4b_row14_col15\" class=\"data row14 col15\" >-0.343324</td>\n","      <td id=\"T_01e4b_row14_col16\" class=\"data row14 col16\" >0.963597</td>\n","      <td id=\"T_01e4b_row14_col17\" class=\"data row14 col17\" >0.053050</td>\n","      <td id=\"T_01e4b_row14_col18\" class=\"data row14 col18\" >0.188492</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row15\" class=\"row_heading level0 row15\" >couldn't</th>\n","      <td id=\"T_01e4b_row15_col0\" class=\"data row15 col0\" >0.165269</td>\n","      <td id=\"T_01e4b_row15_col1\" class=\"data row15 col1\" >-0.980759</td>\n","      <td id=\"T_01e4b_row15_col2\" class=\"data row15 col2\" >0.393873</td>\n","      <td id=\"T_01e4b_row15_col3\" class=\"data row15 col3\" >0.957747</td>\n","      <td id=\"T_01e4b_row15_col4\" class=\"data row15 col4\" >-0.934167</td>\n","      <td id=\"T_01e4b_row15_col5\" class=\"data row15 col5\" >0.596495</td>\n","      <td id=\"T_01e4b_row15_col6\" class=\"data row15 col6\" >0.277634</td>\n","      <td id=\"T_01e4b_row15_col7\" class=\"data row15 col7\" >0.478060</td>\n","      <td id=\"T_01e4b_row15_col8\" class=\"data row15 col8\" >-0.948227</td>\n","      <td id=\"T_01e4b_row15_col9\" class=\"data row15 col9\" >0.431398</td>\n","      <td id=\"T_01e4b_row15_col10\" class=\"data row15 col10\" >-0.922720</td>\n","      <td id=\"T_01e4b_row15_col11\" class=\"data row15 col11\" >-0.464687</td>\n","      <td id=\"T_01e4b_row15_col12\" class=\"data row15 col12\" >0.960960</td>\n","      <td id=\"T_01e4b_row15_col13\" class=\"data row15 col13\" >0.935797</td>\n","      <td id=\"T_01e4b_row15_col14\" class=\"data row15 col14\" >-0.343324</td>\n","      <td id=\"T_01e4b_row15_col15\" class=\"data row15 col15\" >1.000000</td>\n","      <td id=\"T_01e4b_row15_col16\" class=\"data row15 col16\" >-0.428128</td>\n","      <td id=\"T_01e4b_row15_col17\" class=\"data row15 col17\" >-0.328001</td>\n","      <td id=\"T_01e4b_row15_col18\" class=\"data row15 col18\" >-0.339127</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row16\" class=\"row_heading level0 row16\" >have</th>\n","      <td id=\"T_01e4b_row16_col0\" class=\"data row16 col0\" >-0.611046</td>\n","      <td id=\"T_01e4b_row16_col1\" class=\"data row16 col1\" >0.381699</td>\n","      <td id=\"T_01e4b_row16_col2\" class=\"data row16 col2\" >-0.938926</td>\n","      <td id=\"T_01e4b_row16_col3\" class=\"data row16 col3\" >-0.282027</td>\n","      <td id=\"T_01e4b_row16_col4\" class=\"data row16 col4\" >0.341331</td>\n","      <td id=\"T_01e4b_row16_col5\" class=\"data row16 col5\" >-0.928947</td>\n","      <td id=\"T_01e4b_row16_col6\" class=\"data row16 col6\" >-0.336575</td>\n","      <td id=\"T_01e4b_row16_col7\" class=\"data row16 col7\" >-0.940688</td>\n","      <td id=\"T_01e4b_row16_col8\" class=\"data row16 col8\" >0.599535</td>\n","      <td id=\"T_01e4b_row16_col9\" class=\"data row16 col9\" >-0.972917</td>\n","      <td id=\"T_01e4b_row16_col10\" class=\"data row16 col10\" >0.337853</td>\n","      <td id=\"T_01e4b_row16_col11\" class=\"data row16 col11\" >0.929711</td>\n","      <td id=\"T_01e4b_row16_col12\" class=\"data row16 col12\" >-0.409564</td>\n","      <td id=\"T_01e4b_row16_col13\" class=\"data row16 col13\" >-0.334266</td>\n","      <td id=\"T_01e4b_row16_col14\" class=\"data row16 col14\" >0.963597</td>\n","      <td id=\"T_01e4b_row16_col15\" class=\"data row16 col15\" >-0.428128</td>\n","      <td id=\"T_01e4b_row16_col16\" class=\"data row16 col16\" >1.000000</td>\n","      <td id=\"T_01e4b_row16_col17\" class=\"data row16 col17\" >0.172636</td>\n","      <td id=\"T_01e4b_row16_col18\" class=\"data row16 col18\" >0.181561</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row17\" class=\"row_heading level0 row17\" >done</th>\n","      <td id=\"T_01e4b_row17_col0\" class=\"data row17 col0\" >0.267406</td>\n","      <td id=\"T_01e4b_row17_col1\" class=\"data row17 col1\" >0.315982</td>\n","      <td id=\"T_01e4b_row17_col2\" class=\"data row17 col2\" >-0.220974</td>\n","      <td id=\"T_01e4b_row17_col3\" class=\"data row17 col3\" >-0.381295</td>\n","      <td id=\"T_01e4b_row17_col4\" class=\"data row17 col4\" >0.526293</td>\n","      <td id=\"T_01e4b_row17_col5\" class=\"data row17 col5\" >-0.302195</td>\n","      <td id=\"T_01e4b_row17_col6\" class=\"data row17 col6\" >-0.891516</td>\n","      <td id=\"T_01e4b_row17_col7\" class=\"data row17 col7\" >-0.240134</td>\n","      <td id=\"T_01e4b_row17_col8\" class=\"data row17 col8\" >0.352135</td>\n","      <td id=\"T_01e4b_row17_col9\" class=\"data row17 col9\" >-0.256005</td>\n","      <td id=\"T_01e4b_row17_col10\" class=\"data row17 col10\" >0.307556</td>\n","      <td id=\"T_01e4b_row17_col11\" class=\"data row17 col11\" >0.080929</td>\n","      <td id=\"T_01e4b_row17_col12\" class=\"data row17 col12\" >-0.228703</td>\n","      <td id=\"T_01e4b_row17_col13\" class=\"data row17 col13\" >-0.325863</td>\n","      <td id=\"T_01e4b_row17_col14\" class=\"data row17 col14\" >0.053050</td>\n","      <td id=\"T_01e4b_row17_col15\" class=\"data row17 col15\" >-0.328001</td>\n","      <td id=\"T_01e4b_row17_col16\" class=\"data row17 col16\" >0.172636</td>\n","      <td id=\"T_01e4b_row17_col17\" class=\"data row17 col17\" >1.000000</td>\n","      <td id=\"T_01e4b_row17_col18\" class=\"data row17 col18\" >-0.222751</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_01e4b_level0_row18\" class=\"row_heading level0 row18\" >better</th>\n","      <td id=\"T_01e4b_row18_col0\" class=\"data row18 col0\" >-0.307213</td>\n","      <td id=\"T_01e4b_row18_col1\" class=\"data row18 col1\" >0.361057</td>\n","      <td id=\"T_01e4b_row18_col2\" class=\"data row18 col2\" >-0.287265</td>\n","      <td id=\"T_01e4b_row18_col3\" class=\"data row18 col3\" >-0.466580</td>\n","      <td id=\"T_01e4b_row18_col4\" class=\"data row18 col4\" >0.163737</td>\n","      <td id=\"T_01e4b_row18_col5\" class=\"data row18 col5\" >-0.336632</td>\n","      <td id=\"T_01e4b_row18_col6\" class=\"data row18 col6\" >0.073485</td>\n","      <td id=\"T_01e4b_row18_col7\" class=\"data row18 col7\" >-0.263682</td>\n","      <td id=\"T_01e4b_row18_col8\" class=\"data row18 col8\" >0.380753</td>\n","      <td id=\"T_01e4b_row18_col9\" class=\"data row18 col9\" >-0.091362</td>\n","      <td id=\"T_01e4b_row18_col10\" class=\"data row18 col10\" >0.344716</td>\n","      <td id=\"T_01e4b_row18_col11\" class=\"data row18 col11\" >0.314865</td>\n","      <td id=\"T_01e4b_row18_col12\" class=\"data row18 col12\" >-0.499648</td>\n","      <td id=\"T_01e4b_row18_col13\" class=\"data row18 col13\" >-0.519434</td>\n","      <td id=\"T_01e4b_row18_col14\" class=\"data row18 col14\" >0.188492</td>\n","      <td id=\"T_01e4b_row18_col15\" class=\"data row18 col15\" >-0.339127</td>\n","      <td id=\"T_01e4b_row18_col16\" class=\"data row18 col16\" >0.181561</td>\n","      <td id=\"T_01e4b_row18_col17\" class=\"data row18 col17\" >-0.222751</td>\n","      <td id=\"T_01e4b_row18_col18\" class=\"data row18 col18\" >1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["#### Predicción"],"metadata":{"id":"HcqwA1KAL-sw"}},{"cell_type":"code","source":["reviews"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tdJzoA6yhRo","outputId":"1c495151-06cd-411e-d3b1-7b18349ba29a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Never coming back!',\n"," 'horrible service',\n"," 'rude waitress',\n"," 'cold food',\n"," 'horrible food!',\n"," 'awesome',\n"," 'awesome services!',\n"," 'rocks',\n"," 'nice work',\n"," \"couldn't have done better\"]"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# Se definen comentarios adicionales sobre los que se requiere predecir\n","new_reviews  = [\"Nice!\",\n","               \"rude service\",\n","               \"terrible food\"]\n","\n","# Se convierten a una secuencias\n","sequences = tokenizer.texts_to_sequences(new_reviews)\n","\n","# Se rellenan las secuencias\n","new_padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type)\n","\n","# Se predice el sentimiento\n","print(model.predict(new_padded), '\\n', '----'*3)\n","print(np.where(model.predict(new_padded)>0.5, 1, 0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ck-ASvhDqOQ-","outputId":"e69a1b86-507e-441f-c8d3-13b5f7cddbcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.61956495]\n"," [0.36223292]\n"," [0.43261477]] \n"," ------------\n","[[1]\n"," [0]\n"," [0]]\n"]}]},{"cell_type":"markdown","source":["#### RNN"],"metadata":{"id":"6YmvjDiB99jy"}},{"cell_type":"code","source":["from tensorflow.keras.layers import SimpleRNN"],"metadata":{"id":"2JVr5OCVzKnh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_rnn = Sequential()\n","model_rnn.add(embedding_layer)\n","model_rnn.add(SimpleRNN(units=64))\n","model_rnn.add(Dense(1, activation='sigmoid'))\n","\n","model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"WXU091-l-DJS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_rnn.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UM2dDFqi-uSl","outputId":"5fa7b374-4f2c-4b70-e6eb-af839aecbd72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 4, 8)              160       \n","                                                                 \n"," simple_rnn (SimpleRNN)      (None, 64)                4672      \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 4,897\n","Trainable params: 4,897\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_rnn.fit(padded_reviews, labels, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nq_-xAVJ-o0C","outputId":"51920153-ed63-44a1-de04-d02b866ab9cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 [==============================] - 1s 989ms/step - loss: 0.7445 - accuracy: 0.0000e+00\n","Epoch 2/100\n","1/1 [==============================] - 0s 18ms/step - loss: 0.7023 - accuracy: 0.3000\n","Epoch 3/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.6621 - accuracy: 1.0000\n","Epoch 4/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6238 - accuracy: 1.0000\n","Epoch 5/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.5869 - accuracy: 1.0000\n","Epoch 6/100\n","1/1 [==============================] - 0s 17ms/step - loss: 0.5515 - accuracy: 1.0000\n","Epoch 7/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.5171 - accuracy: 1.0000\n","Epoch 8/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.4837 - accuracy: 1.0000\n","Epoch 9/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.4510 - accuracy: 1.0000\n","Epoch 10/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4191 - accuracy: 1.0000\n","Epoch 11/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.3879 - accuracy: 1.0000\n","Epoch 12/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.3573 - accuracy: 1.0000\n","Epoch 13/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.3275 - accuracy: 1.0000\n","Epoch 14/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.2984 - accuracy: 1.0000\n","Epoch 15/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.2703 - accuracy: 1.0000\n","Epoch 16/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.2432 - accuracy: 1.0000\n","Epoch 17/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.2174 - accuracy: 1.0000\n","Epoch 18/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.1929 - accuracy: 1.0000\n","Epoch 19/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.1701 - accuracy: 1.0000\n","Epoch 20/100\n","1/1 [==============================] - 0s 17ms/step - loss: 0.1489 - accuracy: 1.0000\n","Epoch 21/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.1295 - accuracy: 1.0000\n","Epoch 22/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.1120 - accuracy: 1.0000\n","Epoch 23/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0963 - accuracy: 1.0000\n","Epoch 24/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0824 - accuracy: 1.0000\n","Epoch 25/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0704 - accuracy: 1.0000\n","Epoch 26/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0599 - accuracy: 1.0000\n","Epoch 27/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0509 - accuracy: 1.0000\n","Epoch 28/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0433 - accuracy: 1.0000\n","Epoch 29/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0368 - accuracy: 1.0000\n","Epoch 30/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0314 - accuracy: 1.0000\n","Epoch 31/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0269 - accuracy: 1.0000\n","Epoch 32/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 1.0000\n","Epoch 33/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0199 - accuracy: 1.0000\n","Epoch 34/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 1.0000\n","Epoch 35/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 1.0000\n","Epoch 36/100\n","1/1 [==============================] - 0s 18ms/step - loss: 0.0132 - accuracy: 1.0000\n","Epoch 37/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0116 - accuracy: 1.0000\n","Epoch 38/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0103 - accuracy: 1.0000\n","Epoch 39/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 1.0000\n","Epoch 40/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0083 - accuracy: 1.0000\n","Epoch 41/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000\n","Epoch 42/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 1.0000\n","Epoch 43/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0062 - accuracy: 1.0000\n","Epoch 44/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 1.0000\n","Epoch 45/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0053 - accuracy: 1.0000\n","Epoch 46/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 47/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 1.0000\n","Epoch 48/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 49/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 1.0000\n","Epoch 50/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000\n","Epoch 51/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 52/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 53/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 54/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 55/100\n","1/1 [==============================] - 0s 17ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 56/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 57/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 58/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000\n","Epoch 59/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 60/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 61/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 62/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 63/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 64/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 65/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 66/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 67/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 68/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 69/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 70/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 71/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 72/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 73/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 74/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 75/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 76/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 77/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 78/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 79/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 80/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 81/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 82/100\n","1/1 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 83/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 84/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 85/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 86/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 87/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 88/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 89/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 90/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 91/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 92/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 93/100\n","1/1 [==============================] - 0s 19ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 94/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 95/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 96/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 97/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 98/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 99/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 100/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f34de313c90>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["print(model_rnn.predict(new_padded), '\\n', '----'*3)\n","print(np.where(model_rnn.predict(new_padded)>0.5, 1, 0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bORVPGFZ-yEx","outputId":"6271b6b3-d105-4e1c-f418-0ef9f9a6a72d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.9985367 ]\n"," [0.00121384]\n"," [0.04299283]] \n"," ------------\n","[[1]\n"," [0]\n"," [0]]\n"]}]},{"cell_type":"markdown","source":["#### GRU"],"metadata":{"id":"qRU0bRr5_ka4"}},{"cell_type":"code","source":["from tensorflow.keras.layers import GRU"],"metadata":{"id":"IiMmM6bM-8q7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_gru = Sequential()\n","model_gru.add(embedding_layer)\n","model_gru.add(GRU(units=64))\n","model_gru.add(Dense(1, activation='sigmoid'))\n","\n","model_gru.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"aHLZ8Rav_qUu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_gru.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I8ZBEY3a_4nB","outputId":"2d2cb8c9-6987-4847-df78-256ef7bebb21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 4, 8)              160       \n","                                                                 \n"," gru (GRU)                   (None, 64)                14208     \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 14,433\n","Trainable params: 14,433\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_gru.fit(padded_reviews, labels, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gdnsqgOB_9Y-","outputId":"5eaa40c1-f9ce-4807-a94c-59c5baeeef01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 [==============================] - 4s 4s/step - loss: 0.6915 - accuracy: 0.4000\n","Epoch 2/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6894 - accuracy: 0.5000\n","Epoch 3/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6872 - accuracy: 0.5000\n","Epoch 4/100\n","1/1 [==============================] - 0s 18ms/step - loss: 0.6849 - accuracy: 0.9000\n","Epoch 5/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.9000\n","Epoch 6/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.9000\n","Epoch 7/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6779 - accuracy: 0.9000\n","Epoch 8/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6754 - accuracy: 0.9000\n","Epoch 9/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6728 - accuracy: 0.9000\n","Epoch 10/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6701 - accuracy: 0.9000\n","Epoch 11/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6673 - accuracy: 0.9000\n","Epoch 12/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6643 - accuracy: 0.9000\n","Epoch 13/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6611 - accuracy: 0.9000\n","Epoch 14/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.6578 - accuracy: 0.9000\n","Epoch 15/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6542 - accuracy: 0.9000\n","Epoch 16/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6504 - accuracy: 0.9000\n","Epoch 17/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6464 - accuracy: 0.9000\n","Epoch 18/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6421 - accuracy: 0.9000\n","Epoch 19/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6376 - accuracy: 0.9000\n","Epoch 20/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6327 - accuracy: 1.0000\n","Epoch 21/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6275 - accuracy: 1.0000\n","Epoch 22/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.6219 - accuracy: 1.0000\n","Epoch 23/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6159 - accuracy: 1.0000\n","Epoch 24/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.6095 - accuracy: 1.0000\n","Epoch 25/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6026 - accuracy: 1.0000\n","Epoch 26/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.5952 - accuracy: 1.0000\n","Epoch 27/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5872 - accuracy: 1.0000\n","Epoch 28/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.5786 - accuracy: 1.0000\n","Epoch 29/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5695 - accuracy: 1.0000\n","Epoch 30/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5596 - accuracy: 1.0000\n","Epoch 31/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5490 - accuracy: 1.0000\n","Epoch 32/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.5377 - accuracy: 1.0000\n","Epoch 33/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.5255 - accuracy: 1.0000\n","Epoch 34/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.5125 - accuracy: 1.0000\n","Epoch 35/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.4986 - accuracy: 1.0000\n","Epoch 36/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4838 - accuracy: 1.0000\n","Epoch 37/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.4679 - accuracy: 1.0000\n","Epoch 38/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.4511 - accuracy: 1.0000\n","Epoch 39/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.4333 - accuracy: 1.0000\n","Epoch 40/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.4145 - accuracy: 1.0000\n","Epoch 41/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.3947 - accuracy: 1.0000\n","Epoch 42/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.3739 - accuracy: 1.0000\n","Epoch 43/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3522 - accuracy: 1.0000\n","Epoch 44/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.3298 - accuracy: 1.0000\n","Epoch 45/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.3067 - accuracy: 1.0000\n","Epoch 46/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.2830 - accuracy: 1.0000\n","Epoch 47/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.2590 - accuracy: 1.0000\n","Epoch 48/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.2350 - accuracy: 1.0000\n","Epoch 49/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.2111 - accuracy: 1.0000\n","Epoch 50/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.1877 - accuracy: 1.0000\n","Epoch 51/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.1650 - accuracy: 1.0000\n","Epoch 52/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.1434 - accuracy: 1.0000\n","Epoch 53/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.1231 - accuracy: 1.0000\n","Epoch 54/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.1044 - accuracy: 1.0000\n","Epoch 55/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0875 - accuracy: 1.0000\n","Epoch 56/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0725 - accuracy: 1.0000\n","Epoch 57/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0595 - accuracy: 1.0000\n","Epoch 58/100\n","1/1 [==============================] - 0s 23ms/step - loss: 0.0483 - accuracy: 1.0000\n","Epoch 59/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0390 - accuracy: 1.0000\n","Epoch 60/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0313 - accuracy: 1.0000\n","Epoch 61/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 1.0000\n","Epoch 62/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0199 - accuracy: 1.0000\n","Epoch 63/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0159 - accuracy: 1.0000\n","Epoch 64/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 1.0000\n","Epoch 65/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0102 - accuracy: 1.0000\n","Epoch 66/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 1.0000\n","Epoch 67/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 1.0000\n","Epoch 68/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 1.0000\n","Epoch 69/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 70/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 71/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 72/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 73/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 74/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 75/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 76/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 77/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 78/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 79/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 80/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 81/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 82/100\n","1/1 [==============================] - 0s 16ms/step - loss: 9.3894e-04 - accuracy: 1.0000\n","Epoch 83/100\n","1/1 [==============================] - 0s 12ms/step - loss: 8.7526e-04 - accuracy: 1.0000\n","Epoch 84/100\n","1/1 [==============================] - 0s 11ms/step - loss: 8.2017e-04 - accuracy: 1.0000\n","Epoch 85/100\n","1/1 [==============================] - 0s 10ms/step - loss: 7.7227e-04 - accuracy: 1.0000\n","Epoch 86/100\n","1/1 [==============================] - 0s 11ms/step - loss: 7.3042e-04 - accuracy: 1.0000\n","Epoch 87/100\n","1/1 [==============================] - 0s 10ms/step - loss: 6.9367e-04 - accuracy: 1.0000\n","Epoch 88/100\n","1/1 [==============================] - 0s 9ms/step - loss: 6.6127e-04 - accuracy: 1.0000\n","Epoch 89/100\n","1/1 [==============================] - 0s 10ms/step - loss: 6.3256e-04 - accuracy: 1.0000\n","Epoch 90/100\n","1/1 [==============================] - 0s 10ms/step - loss: 6.0704e-04 - accuracy: 1.0000\n","Epoch 91/100\n","1/1 [==============================] - 0s 11ms/step - loss: 5.8424e-04 - accuracy: 1.0000\n","Epoch 92/100\n","1/1 [==============================] - 0s 17ms/step - loss: 5.6381e-04 - accuracy: 1.0000\n","Epoch 93/100\n","1/1 [==============================] - 0s 10ms/step - loss: 5.4543e-04 - accuracy: 1.0000\n","Epoch 94/100\n","1/1 [==============================] - 0s 9ms/step - loss: 5.2884e-04 - accuracy: 1.0000\n","Epoch 95/100\n","1/1 [==============================] - 0s 12ms/step - loss: 5.1381e-04 - accuracy: 1.0000\n","Epoch 96/100\n","1/1 [==============================] - 0s 13ms/step - loss: 5.0015e-04 - accuracy: 1.0000\n","Epoch 97/100\n","1/1 [==============================] - 0s 9ms/step - loss: 4.8769e-04 - accuracy: 1.0000\n","Epoch 98/100\n","1/1 [==============================] - 0s 9ms/step - loss: 4.7629e-04 - accuracy: 1.0000\n","Epoch 99/100\n","1/1 [==============================] - 0s 12ms/step - loss: 4.6583e-04 - accuracy: 1.0000\n","Epoch 100/100\n","1/1 [==============================] - 0s 9ms/step - loss: 4.5619e-04 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f34c83c2a90>"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["print(model_gru.predict(new_padded), '\\n', '----'*3)\n","print(np.where(model_gru.predict(new_padded)>0.5, 1, 0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pyI4_wbt__RV","outputId":"be7950e7-683b-4c66-e26e-1d063b557951"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[9.9938285e-01]\n"," [7.6375692e-04]\n"," [5.1964032e-03]] \n"," ------------\n","[[1]\n"," [0]\n"," [0]]\n"]}]},{"cell_type":"markdown","source":["#### LSTM"],"metadata":{"id":"sOnxmnEOAHUc"}},{"cell_type":"code","source":["from tensorflow.keras.layers import LSTM"],"metadata":{"id":"FrgV1KpgAEaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_lstm = Sequential()\n","model_lstm.add(embedding_layer)\n","model_lstm.add(LSTM(units=64))\n","model_lstm.add(Dense(1, activation='sigmoid'))\n","\n","model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"MouCoRPYANhy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_lstm.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tjYuPqnAUoE","outputId":"f7fa2fd8-89eb-4b06-d113-9b45bdb363d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 4, 8)              160       \n","                                                                 \n"," lstm (LSTM)                 (None, 64)                18688     \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 18,913\n","Trainable params: 18,913\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_lstm.fit(padded_reviews, labels, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jqE366nsAcS7","outputId":"23170ef1-08be-41e7-b6ab-f17465583a86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 [==============================] - 2s 2s/step - loss: 0.6955 - accuracy: 0.5000\n","Epoch 2/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6916 - accuracy: 0.5000\n","Epoch 3/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6878 - accuracy: 0.6000\n","Epoch 4/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6839 - accuracy: 0.6000\n","Epoch 5/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.6800 - accuracy: 0.6000\n","Epoch 6/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6761 - accuracy: 0.8000\n","Epoch 7/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6721 - accuracy: 1.0000\n","Epoch 8/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6679 - accuracy: 1.0000\n","Epoch 9/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6637 - accuracy: 1.0000\n","Epoch 10/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6594 - accuracy: 1.0000\n","Epoch 11/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6549 - accuracy: 1.0000\n","Epoch 12/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6502 - accuracy: 1.0000\n","Epoch 13/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6453 - accuracy: 1.0000\n","Epoch 14/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6401 - accuracy: 1.0000\n","Epoch 15/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6347 - accuracy: 1.0000\n","Epoch 16/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6291 - accuracy: 1.0000\n","Epoch 17/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.6231 - accuracy: 1.0000\n","Epoch 18/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6167 - accuracy: 1.0000\n","Epoch 19/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6100 - accuracy: 1.0000\n","Epoch 20/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6029 - accuracy: 1.0000\n","Epoch 21/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.5953 - accuracy: 1.0000\n","Epoch 22/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5872 - accuracy: 1.0000\n","Epoch 23/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5786 - accuracy: 1.0000\n","Epoch 24/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5695 - accuracy: 1.0000\n","Epoch 25/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5597 - accuracy: 1.0000\n","Epoch 26/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.5494 - accuracy: 1.0000\n","Epoch 27/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5383 - accuracy: 1.0000\n","Epoch 28/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5266 - accuracy: 1.0000\n","Epoch 29/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5141 - accuracy: 1.0000\n","Epoch 30/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.5009 - accuracy: 1.0000\n","Epoch 31/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4869 - accuracy: 1.0000\n","Epoch 32/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.4721 - accuracy: 1.0000\n","Epoch 33/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.4565 - accuracy: 1.0000\n","Epoch 34/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.4401 - accuracy: 1.0000\n","Epoch 35/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4229 - accuracy: 1.0000\n","Epoch 36/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4049 - accuracy: 1.0000\n","Epoch 37/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.3861 - accuracy: 1.0000\n","Epoch 38/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.3667 - accuracy: 1.0000\n","Epoch 39/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3467 - accuracy: 1.0000\n","Epoch 40/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.3262 - accuracy: 1.0000\n","Epoch 41/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.3053 - accuracy: 1.0000\n","Epoch 42/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.2841 - accuracy: 1.0000\n","Epoch 43/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2629 - accuracy: 1.0000\n","Epoch 44/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2417 - accuracy: 1.0000\n","Epoch 45/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.2209 - accuracy: 1.0000\n","Epoch 46/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2004 - accuracy: 1.0000\n","Epoch 47/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.1807 - accuracy: 1.0000\n","Epoch 48/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.1618 - accuracy: 1.0000\n","Epoch 49/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.1440 - accuracy: 1.0000\n","Epoch 50/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.1273 - accuracy: 1.0000\n","Epoch 51/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.1120 - accuracy: 1.0000\n","Epoch 52/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0980 - accuracy: 1.0000\n","Epoch 53/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0853 - accuracy: 1.0000\n","Epoch 54/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0741 - accuracy: 1.0000\n","Epoch 55/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0642 - accuracy: 1.0000\n","Epoch 56/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0555 - accuracy: 1.0000\n","Epoch 57/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0480 - accuracy: 1.0000\n","Epoch 58/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0416 - accuracy: 1.0000\n","Epoch 59/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0361 - accuracy: 1.0000\n","Epoch 60/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0313 - accuracy: 1.0000\n","Epoch 61/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 1.0000\n","Epoch 62/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0239 - accuracy: 1.0000\n","Epoch 63/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 1.0000\n","Epoch 64/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 1.0000\n","Epoch 65/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0165 - accuracy: 1.0000\n","Epoch 66/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 1.0000\n","Epoch 67/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0133 - accuracy: 1.0000\n","Epoch 68/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 1.0000\n","Epoch 69/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 1.0000\n","Epoch 70/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0099 - accuracy: 1.0000\n","Epoch 71/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 1.0000\n","Epoch 72/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 1.0000\n","Epoch 73/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 1.0000\n","Epoch 74/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 1.0000\n","Epoch 75/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 1.0000\n","Epoch 76/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0062 - accuracy: 1.0000\n","Epoch 77/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0058 - accuracy: 1.0000\n","Epoch 78/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 1.0000\n","Epoch 79/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 1.0000\n","Epoch 80/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 81/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 1.0000\n","Epoch 82/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 1.0000\n","Epoch 83/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 84/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 1.0000\n","Epoch 85/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 86/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000\n","Epoch 87/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 88/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000\n","Epoch 89/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 90/100\n","1/1 [==============================] - 0s 19ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 91/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 92/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 93/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 94/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 95/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 96/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 97/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 98/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000\n","Epoch 99/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 100/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f34d96e1390>"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["print(model_lstm.predict(new_padded), '\\n', '----'*3)\n","print(np.where(model_lstm.predict(new_padded)>0.5, 1, 0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O5p_OwFWAeRV","outputId":"a119c90b-6877-4dfb-febb-7d24b81d20bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.99685705]\n"," [0.00231003]\n"," [0.0254944 ]] \n"," ------------\n","[[1]\n"," [0]\n"," [0]]\n"]}]},{"cell_type":"markdown","source":["#### Bidireccional"],"metadata":{"id":"k-ky33iDAl3S"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Bidirectional"],"metadata":{"id":"6Bl4VhXPAiiD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_bd = Sequential()\n","model_bd.add(embedding_layer)\n","model_bd.add(Bidirectional(layer=LSTM(units=64)))\n","model_bd.add(Dense(1, activation='sigmoid'))\n","\n","model_bd.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"TbpZ0Zb-Axs8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_bd.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NhkDMp6oBBZc","outputId":"c8e6a2d7-d28f-416b-c706-79deefdd241e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 4, 8)              160       \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 128)              37376     \n"," l)                                                              \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 37,665\n","Trainable params: 37,665\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_bd.fit(padded_reviews, labels, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m2l3ui1zBD40","outputId":"24c35aef-a1a6-4892-9d2f-783fca83ce2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 [==============================] - 3s 3s/step - loss: 0.7159 - accuracy: 0.0000e+00\n","Epoch 2/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.7075 - accuracy: 0.0000e+00\n","Epoch 3/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6992 - accuracy: 0.4000\n","Epoch 4/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6910 - accuracy: 0.5000\n","Epoch 5/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6828 - accuracy: 0.6000\n","Epoch 6/100\n","1/1 [==============================] - 0s 17ms/step - loss: 0.6747 - accuracy: 0.6000\n","Epoch 7/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6665 - accuracy: 0.6000\n","Epoch 8/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6583 - accuracy: 1.0000\n","Epoch 9/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6500 - accuracy: 1.0000\n","Epoch 10/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6416 - accuracy: 1.0000\n","Epoch 11/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6331 - accuracy: 1.0000\n","Epoch 12/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6243 - accuracy: 1.0000\n","Epoch 13/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6153 - accuracy: 1.0000\n","Epoch 14/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.6061 - accuracy: 1.0000\n","Epoch 15/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5965 - accuracy: 1.0000\n","Epoch 16/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5867 - accuracy: 1.0000\n","Epoch 17/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5764 - accuracy: 1.0000\n","Epoch 18/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.5658 - accuracy: 1.0000\n","Epoch 19/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5548 - accuracy: 1.0000\n","Epoch 20/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.5433 - accuracy: 1.0000\n","Epoch 21/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.5314 - accuracy: 1.0000\n","Epoch 22/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5189 - accuracy: 1.0000\n","Epoch 23/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5059 - accuracy: 1.0000\n","Epoch 24/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.4924 - accuracy: 1.0000\n","Epoch 25/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4784 - accuracy: 1.0000\n","Epoch 26/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.4638 - accuracy: 1.0000\n","Epoch 27/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.4486 - accuracy: 1.0000\n","Epoch 28/100\n","1/1 [==============================] - 0s 18ms/step - loss: 0.4329 - accuracy: 1.0000\n","Epoch 29/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.4166 - accuracy: 1.0000\n","Epoch 30/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.3997 - accuracy: 1.0000\n","Epoch 31/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.3824 - accuracy: 1.0000\n","Epoch 32/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3646 - accuracy: 1.0000\n","Epoch 33/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3464 - accuracy: 1.0000\n","Epoch 34/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3279 - accuracy: 1.0000\n","Epoch 35/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3090 - accuracy: 1.0000\n","Epoch 36/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.2900 - accuracy: 1.0000\n","Epoch 37/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.2709 - accuracy: 1.0000\n","Epoch 38/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.2518 - accuracy: 1.0000\n","Epoch 39/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.2328 - accuracy: 1.0000\n","Epoch 40/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.2142 - accuracy: 1.0000\n","Epoch 41/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.1959 - accuracy: 1.0000\n","Epoch 42/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.1782 - accuracy: 1.0000\n","Epoch 43/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.1611 - accuracy: 1.0000\n","Epoch 44/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.1449 - accuracy: 1.0000\n","Epoch 45/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.1295 - accuracy: 1.0000\n","Epoch 46/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.1152 - accuracy: 1.0000\n","Epoch 47/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.1019 - accuracy: 1.0000\n","Epoch 48/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0897 - accuracy: 1.0000\n","Epoch 49/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0787 - accuracy: 1.0000\n","Epoch 50/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0687 - accuracy: 1.0000\n","Epoch 51/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0599 - accuracy: 1.0000\n","Epoch 52/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0520 - accuracy: 1.0000\n","Epoch 53/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0452 - accuracy: 1.0000\n","Epoch 54/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0392 - accuracy: 1.0000\n","Epoch 55/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0340 - accuracy: 1.0000\n","Epoch 56/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0295 - accuracy: 1.0000\n","Epoch 57/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0257 - accuracy: 1.0000\n","Epoch 58/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0224 - accuracy: 1.0000\n","Epoch 59/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 1.0000\n","Epoch 60/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 1.0000\n","Epoch 61/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0151 - accuracy: 1.0000\n","Epoch 62/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 1.0000\n","Epoch 63/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 1.0000\n","Epoch 64/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0106 - accuracy: 1.0000\n","Epoch 65/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 1.0000\n","Epoch 66/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000\n","Epoch 67/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 1.0000\n","Epoch 68/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 1.0000\n","Epoch 69/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 1.0000\n","Epoch 70/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 1.0000\n","Epoch 71/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 1.0000\n","Epoch 72/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 1.0000\n","Epoch 73/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000\n","Epoch 74/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0044 - accuracy: 1.0000\n","Epoch 75/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 1.0000\n","Epoch 76/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 77/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 78/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 79/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 80/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 81/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 82/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 83/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 84/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000\n","Epoch 85/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 86/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 87/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 88/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 89/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 90/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 91/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 92/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 93/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 94/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 95/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 96/100\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 97/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 98/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 99/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 100/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f34d8febed0>"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["print(model_bd.predict(new_padded), '\\n', '----'*3)\n","print(np.where(model_bd.predict(new_padded)>0.5, 1, 0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sE42cjRaCPoh","outputId":"48220ed4-6e2c-4808-fa02-7779f1c11db6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f34d90787a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.99805945]\n"," [0.00213523]\n"," [0.0276983 ]] \n"," ------------\n","[[1]\n"," [0]\n"," [0]]\n"]}]},{"cell_type":"markdown","source":["#### Convolución 1D"],"metadata":{"id":"9x5PO_Y6CYfr"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D"],"metadata":{"id":"bRWkbdk3CULo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[Global Average Pooling](https://paperswithcode.com/method/global-average-pooling)"],"metadata":{"id":"lYpX-zigD63n"}},{"cell_type":"code","source":["model_conv = Sequential()\n","model_conv.add(embedding_layer)\n","model_conv.add(Conv1D(filters=8, kernel_size=3, activation='relu'))\n","model_conv.add(GlobalAveragePooling1D())\n","model_conv.add(Dense(1, activation='sigmoid'))\n","\n","model_conv.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"pTM8tStsCurA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_conv.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gjxSBdS1C9ii","outputId":"41936233-900f-48d3-8538-b5b10687ba7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 4, 8)              160       \n","                                                                 \n"," conv1d (Conv1D)             (None, 2, 8)              200       \n","                                                                 \n"," global_average_pooling1d (G  (None, 8)                0         \n"," lobalAveragePooling1D)                                          \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 369\n","Trainable params: 369\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_conv.fit(padded_reviews, labels, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4PaVf45DmB8","outputId":"f99631ac-8c59-4b5d-ad72-a6a3812e48a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 [==============================] - 8s 8s/step - loss: 0.6880 - accuracy: 0.5000\n","Epoch 2/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5000\n","Epoch 3/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6751 - accuracy: 0.6000\n","Epoch 4/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6686 - accuracy: 0.8000\n","Epoch 5/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6621 - accuracy: 0.9000\n","Epoch 6/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6556 - accuracy: 1.0000\n","Epoch 7/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.6491 - accuracy: 1.0000\n","Epoch 8/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6425 - accuracy: 1.0000\n","Epoch 9/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6360 - accuracy: 1.0000\n","Epoch 10/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6296 - accuracy: 1.0000\n","Epoch 11/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6231 - accuracy: 1.0000\n","Epoch 12/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6167 - accuracy: 1.0000\n","Epoch 13/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6103 - accuracy: 1.0000\n","Epoch 14/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.6039 - accuracy: 1.0000\n","Epoch 15/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.5977 - accuracy: 1.0000\n","Epoch 16/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.5915 - accuracy: 1.0000\n","Epoch 17/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5854 - accuracy: 1.0000\n","Epoch 18/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5793 - accuracy: 1.0000\n","Epoch 19/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5732 - accuracy: 1.0000\n","Epoch 20/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.5671 - accuracy: 1.0000\n","Epoch 21/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5611 - accuracy: 1.0000\n","Epoch 22/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5551 - accuracy: 1.0000\n","Epoch 23/100\n","1/1 [==============================] - 0s 19ms/step - loss: 0.5491 - accuracy: 1.0000\n","Epoch 24/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.5432 - accuracy: 1.0000\n","Epoch 25/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.5374 - accuracy: 1.0000\n","Epoch 26/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.5316 - accuracy: 1.0000\n","Epoch 27/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.5259 - accuracy: 1.0000\n","Epoch 28/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5203 - accuracy: 1.0000\n","Epoch 29/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5146 - accuracy: 1.0000\n","Epoch 30/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5090 - accuracy: 1.0000\n","Epoch 31/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5034 - accuracy: 1.0000\n","Epoch 32/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.4978 - accuracy: 1.0000\n","Epoch 33/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4922 - accuracy: 1.0000\n","Epoch 34/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4867 - accuracy: 1.0000\n","Epoch 35/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4811 - accuracy: 1.0000\n","Epoch 36/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.4756 - accuracy: 1.0000\n","Epoch 37/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.4699 - accuracy: 1.0000\n","Epoch 38/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.4643 - accuracy: 1.0000\n","Epoch 39/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4587 - accuracy: 1.0000\n","Epoch 40/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4530 - accuracy: 1.0000\n","Epoch 41/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.4474 - accuracy: 1.0000\n","Epoch 42/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.4418 - accuracy: 1.0000\n","Epoch 43/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4362 - accuracy: 1.0000\n","Epoch 44/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4306 - accuracy: 1.0000\n","Epoch 45/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4250 - accuracy: 1.0000\n","Epoch 46/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4193 - accuracy: 1.0000\n","Epoch 47/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4136 - accuracy: 1.0000\n","Epoch 48/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4080 - accuracy: 1.0000\n","Epoch 49/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.4023 - accuracy: 1.0000\n","Epoch 50/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.3967 - accuracy: 1.0000\n","Epoch 51/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.3912 - accuracy: 1.0000\n","Epoch 52/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.3857 - accuracy: 1.0000\n","Epoch 53/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.3803 - accuracy: 1.0000\n","Epoch 54/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.3749 - accuracy: 1.0000\n","Epoch 55/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3696 - accuracy: 1.0000\n","Epoch 56/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3643 - accuracy: 1.0000\n","Epoch 57/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.3591 - accuracy: 1.0000\n","Epoch 58/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.3540 - accuracy: 1.0000\n","Epoch 59/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.3489 - accuracy: 1.0000\n","Epoch 60/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.3440 - accuracy: 1.0000\n","Epoch 61/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.3391 - accuracy: 1.0000\n","Epoch 62/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3344 - accuracy: 1.0000\n","Epoch 63/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3297 - accuracy: 1.0000\n","Epoch 64/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.3252 - accuracy: 1.0000\n","Epoch 65/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.3208 - accuracy: 1.0000\n","Epoch 66/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.3165 - accuracy: 1.0000\n","Epoch 67/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.3122 - accuracy: 1.0000\n","Epoch 68/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.3081 - accuracy: 1.0000\n","Epoch 69/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.3041 - accuracy: 1.0000\n","Epoch 70/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.3001 - accuracy: 1.0000\n","Epoch 71/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2962 - accuracy: 1.0000\n","Epoch 72/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.2923 - accuracy: 1.0000\n","Epoch 73/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.2886 - accuracy: 1.0000\n","Epoch 74/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.2849 - accuracy: 1.0000\n","Epoch 75/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.2812 - accuracy: 1.0000\n","Epoch 76/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.2776 - accuracy: 1.0000\n","Epoch 77/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.2740 - accuracy: 1.0000\n","Epoch 78/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.2705 - accuracy: 1.0000\n","Epoch 79/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.2670 - accuracy: 1.0000\n","Epoch 80/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.2635 - accuracy: 1.0000\n","Epoch 81/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.2601 - accuracy: 1.0000\n","Epoch 82/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.2567 - accuracy: 1.0000\n","Epoch 83/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.2533 - accuracy: 1.0000\n","Epoch 84/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.2500 - accuracy: 1.0000\n","Epoch 85/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.2467 - accuracy: 1.0000\n","Epoch 86/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2434 - accuracy: 1.0000\n","Epoch 87/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.2401 - accuracy: 1.0000\n","Epoch 88/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.2368 - accuracy: 1.0000\n","Epoch 89/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.2335 - accuracy: 1.0000\n","Epoch 90/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.2303 - accuracy: 1.0000\n","Epoch 91/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.2272 - accuracy: 1.0000\n","Epoch 92/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2240 - accuracy: 1.0000\n","Epoch 93/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2209 - accuracy: 1.0000\n","Epoch 94/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.2179 - accuracy: 1.0000\n","Epoch 95/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.2148 - accuracy: 1.0000\n","Epoch 96/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.2119 - accuracy: 1.0000\n","Epoch 97/100\n","1/1 [==============================] - 0s 9ms/step - loss: 0.2089 - accuracy: 1.0000\n","Epoch 98/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.2060 - accuracy: 1.0000\n","Epoch 99/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.2031 - accuracy: 1.0000\n","Epoch 100/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.2002 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f34ba18c150>"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["print(model_conv.predict(new_padded), '\\n', '----'*3)\n","print(np.where(model_conv.predict(new_padded)>0.5, 1, 0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8MrypyEQDsh5","outputId":"64f5c078-396e-4a56-d71d-696ff3ee3f8c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f34ba1a5290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["[[0.7862312 ]\n"," [0.1831048 ]\n"," [0.26949495]] \n"," ------------\n","[[1]\n"," [0]\n"," [0]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9vcmOOO2bVFp"},"execution_count":null,"outputs":[]}]}