{"cells":[{"cell_type":"code","execution_count":222,"metadata":{},"outputs":[],"source":["from pyspark import SparkContext,HiveContext\n","from pyspark.sql import SQLContext,SparkSession\n","from pyspark.sql import functions as F\n","from pyspark.sql.dataframe import DataFrame\n","\n","from pyspark.ml.feature import VectorAssembler,Imputer\n","from pyspark.ml.regression import GBTRegressor,LinearRegression\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","import numpy as np\n","import pandas as pd\n","\n","from itertools import combinations\n","from functools import reduce\n","\n","from datetime import date,datetime\n","from dateutil.relativedelta import relativedelta as rd\n","\n","from sklearn.model_selection import train_test_split\n","\n","import asyncio"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["sqlContext = SQLContext(spark)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 763 µs, sys: 4.19 ms, total: 4.95 ms\n","Wall time: 2.02 s\n"]}],"source":["%%time\n","df = spark.read.parquet('/stocks_clean/*.parquet')"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- date: timestamp (nullable = true)\n"," |-- volume: double (nullable = true)\n"," |-- open: double (nullable = true)\n"," |-- high: double (nullable = true)\n"," |-- low: double (nullable = true)\n"," |-- close: double (nullable = true)\n"," |-- stock: string (nullable = true)\n"," |-- dif: double (nullable = true)\n","\n"]}],"source":["df = df.withColumn('dif',df.high-df.low)\n","df.printSchema()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["varc = ['volume','open','high','low','close','dif']"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["df = df.filter(df['date']>=date(2011,1,1))"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["df.registerTempTable('acciones')"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["query = \"\"\"\n","SELECT stock,date,count(*) as casos FROM \n","acciones \n","GROUP BY stock,date\n","having count(*)>1\n","\"\"\""]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+----+-----+\n","|stock|date|casos|\n","+-----+----+-----+\n","+-----+----+-----+\n","\n"]}],"source":["sqlContext.sql(query).show()"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>mes</th>\n","      <th>id_mes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2384</th>\n","      <td>2016-12-19</td>\n","      <td>201612</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>2385</th>\n","      <td>2016-12-21</td>\n","      <td>201612</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>2386</th>\n","      <td>2016-12-28</td>\n","      <td>201612</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>2387</th>\n","      <td>2016-12-07</td>\n","      <td>201612</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>2388</th>\n","      <td>2016-12-02</td>\n","      <td>201612</td>\n","      <td>72</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           date     mes  id_mes\n","2384 2016-12-19  201612      72\n","2385 2016-12-21  201612      72\n","2386 2016-12-28  201612      72\n","2387 2016-12-07  201612      72\n","2388 2016-12-02  201612      72"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["catfh = df.select('date').dropDuplicates().toPandas()\n","catfh['mes'] = catfh['date'].map(lambda x:x.strftime('%Y%m'))\n","aux = catfh[['mes']].drop_duplicates().sort_values(by='mes').reset_index(drop=True)\n","aux.insert(0,'id_mes',aux.index+1)\n","catfh = catfh.merge(aux,on='mes',how='inner')\n","catfh = catfh.loc[catfh['id_mes']<115].reset_index(drop=True)\n","catfh.tail()"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["catfh = spark.createDataFrame(catfh[['date','id_mes']])"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["df = df.join(catfh,['date'],'inner')"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- date: timestamp (nullable = true)\n"," |-- volume: double (nullable = true)\n"," |-- open: double (nullable = true)\n"," |-- high: double (nullable = true)\n"," |-- low: double (nullable = true)\n"," |-- close: double (nullable = true)\n"," |-- stock: string (nullable = true)\n"," |-- dif: double (nullable = true)\n"," |-- id_mes: long (nullable = true)\n","\n"]}],"source":["df.printSchema()\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["vobs = 12\n","vdes = 1\n","step = 3\n"]},{"cell_type":"code","execution_count":183,"metadata":{},"outputs":[],"source":["def ingX(df:DataFrame,ancla:int,sub:int)->DataFrame:\n","    aux = df.filter((df['id_mes']<=ancla)&(df['id_mes']>=(ancla-sub+1)))\n","    aux.registerTempTable('aux')\n","    query = f\"\"\"\n","                with defase as (\n","                  SELECT \n","                    stock, \n","                    date, \n","                    close, \n","                    lag(close,-1) over (\n","                      partition by stock \n","                      order by \n","                        date desc\n","                    ) as previa \n","                  from \n","                    aux \n","                  order by \n","                    stock, \n","                    date desc\n","                ) \n","                select \n","                  stock, \n","                  {ancla} as ancla, \n","                  avg(\n","                    (close - previa)/ close\n","                  ) as x_incpct_prom_{sub}, \n","                  avg(\n","                    case when close > previa then 1 else 0 end\n","                  ) as x_num_incprecio_{sub}, \n","                  avg(\n","                    case when close < previa then 1 else 0 end\n","                  ) as x_num_deccprecio_{sub} \n","                from \n","                  defase \n","                group by \n","                  stock\n","\n","            \"\"\" \n","    piv = sqlContext.sql(query)\n","    for v1,v2 in combinations(varc,2):\n","        aux = aux.withColumn(f'ratio_{v1}_{v2}',aux[v1]/aux[v2])\n","    \n","    ratios = [v for v in aux.columns if v.startswith('ratio_')]    \n","    expr = [f(F.col(v)).alias(f'x_{n}_{v}_{sub}') for v in varc+ratios for f,n in zip([F.min,F.max,F.mean,F.stddev],['min','max','mean','std'])]\n","    aux =aux.groupBy('stock').agg(*expr)\n","    aux = aux.withColumn('ancla',F.lit(ancla))\n","    return aux.join(piv,['stock','ancla'],'inner')"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[{"data":{"text/plain":["(12, 113)"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["anclai, anclaf = df.select('id_mes').dropDuplicates().toPandas().agg(['min','max']).T.values[0]\n","anclai, anclaf = anclai+vobs-1,anclaf-vdes\n","anclai, anclaf"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[],"source":["cruzar = lambda x,y: x.join(y,um,'outer')\n","apilar = lambda x,y: x.union(y)"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[],"source":["um = ['stock','ancla']"]},{"cell_type":"code","execution_count":184,"metadata":{},"outputs":[],"source":["async def repVect (ancla:int):\n","    print(f\"generando X ({ancla})\")\n","    aux = reduce(cruzar,map(lambda sub:ingX(df,ancla,sub),range(step,vobs+step,step)))\n","    ancla = \"%03d\"%ancla\n","    aux.write.parquet(f'/stocks_feature/X_{ancla}.parquet',mode='overwrite') "]},{"cell_type":"code","execution_count":185,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["generando X (12)\n","generando X (13)\n","generando X (14)\n","generando X (15)\n","generando X (16)\n"]},{"data":{"text/plain":["[None, None, None, None, None]"]},"execution_count":185,"metadata":{},"output_type":"execute_result"}],"source":["await asyncio.gather(*map(repVect,range(anclai,anclai+5)))"]},{"cell_type":"code","execution_count":176,"metadata":{},"outputs":[],"source":["async def ingY(df:DataFrame,ancla:int)->DataFrame:\n","    print(f\"generando Y ({ancla})\")\n","    aux = df.filter((df['id_mes']>ancla)&(df['id_mes']<=(ancla+vdes))).select(*['stock','date','close','id_mes'])\n","    aux.registerTempTable('aux')\n","    query = f\"\"\"\n","            with max_fh as (\n","          select \n","            stock, \n","            max(date) as date \n","          from \n","            aux \n","          group by \n","            stock\n","        ) \n","        select \n","          stock, \n","          {ancla} as ancla,\n","          close as cierre_sig_mes \n","        from \n","          aux \n","          inner join max_fh using(stock, date)\n","\n","        \"\"\"\n","    ancla = \"%03d\"%ancla\n","    sqlContext.sql(query).write.parquet(f'/stocks_feature/Y_{ancla}.parquet',mode='overwrite') "]},{"cell_type":"code","execution_count":177,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["generando Y (12)\n","generando Y (13)\n","generando Y (14)\n","generando Y (15)\n","generando Y (16)\n"]},{"data":{"text/plain":["[None, None, None, None, None]"]},"execution_count":177,"metadata":{},"output_type":"execute_result"}],"source":["await asyncio.gather(*map(lambda ancla:ingY(df,ancla),range(anclai,anclai+5)))"]},{"cell_type":"code","execution_count":190,"metadata":{},"outputs":[],"source":["best = ['x_max_high_3','x_min_ratio_volume_high_12','x_min_ratio_open_dif_9','x_min_ratio_high_low_9']"]},{"cell_type":"code","execution_count":192,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- stock: string (nullable = true)\n"," |-- ancla: integer (nullable = true)\n"," |-- x_max_high_3: double (nullable = true)\n"," |-- x_min_ratio_volume_high_12: double (nullable = true)\n"," |-- x_min_ratio_open_dif_9: double (nullable = true)\n"," |-- x_min_ratio_high_low_9: double (nullable = true)\n"," |-- cierre_sig_mes: double (nullable = true)\n","\n","CPU times: user 10.4 ms, sys: 0 ns, total: 10.4 ms\n","Wall time: 654 ms\n"]}],"source":["%%time \n","X = spark.read.parquet('/stocks_feature/X_*.parquet')\n","y = spark.read.parquet('/stocks_feature/Y_*.parquet')\n","tad = X.join(y,um,'inner').select(*(um+best+['cierre_sig_mes']))\n","tad.printSchema()"]},{"cell_type":"code","execution_count":193,"metadata":{},"outputs":[],"source":["train,valid = train_test_split(tad.toPandas(),train_size=0.7)\n","train,valid = spark.createDataFrame(train),spark.createDataFrame(valid)"]},{"cell_type":"code","execution_count":194,"metadata":{},"outputs":[],"source":["# Imputación\n","imp = Imputer(strategy='median',inputCols=best,outputCols=best)\n","imp = imp.fit(train)\n","Xi = imp.transform(train)"]},{"cell_type":"code","execution_count":198,"metadata":{},"outputs":[],"source":["# Vectorización\n","assembler = VectorAssembler(inputCols=best,outputCol='vector')\n","v = assembler.transform(Xi)\n","v.printSchema()"]},{"cell_type":"code","execution_count":223,"metadata":{},"outputs":[],"source":["# Modelo\n","mod = LinearRegression(featuresCol='vector',labelCol='cierre_sig_mes')"]},{"cell_type":"code","execution_count":224,"metadata":{},"outputs":[],"source":["mod = mod.fit(v)"]},{"cell_type":"code","execution_count":225,"metadata":{},"outputs":[],"source":["ev = RegressionEvaluator(labelCol='cierre_sig_mes',metricName='mae')"]},{"cell_type":"code","execution_count":226,"metadata":{},"outputs":[{"data":{"text/plain":["110.30206997418219"]},"execution_count":226,"metadata":{},"output_type":"execute_result"}],"source":["ev.evaluate(mod.transform(v))"]},{"cell_type":"code","execution_count":227,"metadata":{},"outputs":[{"data":{"text/plain":["74.04249293540894"]},"execution_count":227,"metadata":{},"output_type":"execute_result"}],"source":["ev.evaluate(mod.transform(assembler.transform(imp.transform(valid))))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":2}